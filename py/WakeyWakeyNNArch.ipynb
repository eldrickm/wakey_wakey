{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WakeyWakeyNNArch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbiiMcdNJI--"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3RF5VmcoUMG"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC8yT1DaxkS0"
      },
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "API_KEY = 'ei_9eedce842a674656748bf65a19f0e2a80cc867cde21a7810354f75a4fb565a3d'\n",
        "\n",
        "#X = (requests.get('https://studio.edgeimpulse.com/v1/api/24007/training/9/x', headers={'x-api-key': API_KEY})).content\n",
        "#Y = (requests.get('https://studio.edgeimpulse.com/v1/api/24007/training/9/y', headers={'x-api-key': API_KEY})).content\n",
        "X = (requests.get('https://studio.edgeimpulse.com/v1/api/24007/dsp-data/3/x/training', headers={'x-api-key': API_KEY})).content\n",
        "Y = (requests.get('https://studio.edgeimpulse.com/v1/api/24007/dsp-data/3/y/training', headers={'x-api-key': API_KEY})).content\n",
        "Xtest = (requests.get('https://studio.edgeimpulse.com/v1/api/24007/dsp-data/3/x/testing', headers={'x-api-key': API_KEY})).content\n",
        "Ytest = (requests.get('https://studio.edgeimpulse.com/v1/api/24007/dsp-data/3/y/testing', headers={'x-api-key': API_KEY})).content\n",
        "with open('x_train.npy', 'wb') as file:\n",
        "    file.write(X)\n",
        "with open('y_train.npy', 'wb') as file:\n",
        "    file.write(Y)\n",
        "with open('x_test.npy', 'wb') as file:\n",
        "    file.write(Xtest)\n",
        "with open('y_test.npy', 'wb') as file:\n",
        "    file.write(Ytest)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4MbRogAxr9U"
      },
      "source": [
        "X = np.load('x_train.npy')\n",
        "Y = np.load('y_train.npy')[:,0]\n",
        "Xtest = np.load('x_test.npy')\n",
        "Ytest = np.load('y_test.npy')[:,0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fL3F-7Rntog"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(13, 8, 3, padding=1, bias=False)\n",
        "        self.pool = nn.MaxPool1d(2, 2, ceil_mode=True)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.conv2 = nn.Conv1d(8, 16, 3, padding=1, bias=False)\n",
        "        self.fc1 = nn.Linear(16 * 13, 3, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.reshape((x.shape[0], 50, 13)).transpose(1, 2)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = x.reshape((x.shape[0], 16*13))\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzK6ohj5oNCT"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 500\n",
        "\n",
        "Y_tensor = torch.Tensor(Y-1).type(torch.int64)\n",
        "trainset = TensorDataset(torch.Tensor(X), Y_tensor)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "\n",
        "Ytest_tensor = torch.Tensor(Ytest-1).type(torch.int64)\n",
        "testset = TensorDataset(torch.Tensor(Xtest), Ytest_tensor)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)\n",
        "\n",
        "def train(model: nn.Module, dataloader: DataLoader):\n",
        "    model.train()  # turn on dropout layers\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        #for i in range(len(X)):\n",
        "        #    inputs = torch.tensor(X[i,:]).reshape((1, 650))\n",
        "        #    labels = torch.tensor(Y[i] - 1, dtype=torch.int64).reshape(1)\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "        if epoch % 10 == 9:\n",
        "            print('[%d] loss: %.3f' % (epoch + 1, running_loss))\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "def test(model: nn.Module, dataloader: DataLoader, max_samples=None) -> float:\n",
        "    model.eval()  # turn off dropout layers\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    n_inferences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #for i in range(len(X)):\n",
        "        #    inputs = torch.tensor(X[i,:]).reshape((1, 650))\n",
        "        #    labels = torch.tensor(Y[i]).reshape(1)\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if max_samples:\n",
        "                n_inferences += inputs.shape[0]\n",
        "                if n_inferences > max_samples:\n",
        "                    break\n",
        "    \n",
        "    return 100 * correct / total"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HixhBHaqtmZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae27e94-4f7e-46c4-88b2-7b28ebd9c4e7"
      },
      "source": [
        "train(net, trainloader)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10] loss: 113.029\n",
            "[20] loss: 97.595\n",
            "[30] loss: 86.946\n",
            "[40] loss: 78.125\n",
            "[50] loss: 69.315\n",
            "[60] loss: 59.536\n",
            "[70] loss: 56.522\n",
            "[80] loss: 47.868\n",
            "[90] loss: 45.654\n",
            "[100] loss: 42.056\n",
            "[110] loss: 39.744\n",
            "[120] loss: 39.364\n",
            "[130] loss: 36.254\n",
            "[140] loss: 33.837\n",
            "[150] loss: 34.910\n",
            "[160] loss: 35.280\n",
            "[170] loss: 32.570\n",
            "[180] loss: 32.215\n",
            "[190] loss: 31.873\n",
            "[200] loss: 30.058\n",
            "[210] loss: 31.125\n",
            "[220] loss: 30.524\n",
            "[230] loss: 29.862\n",
            "[240] loss: 30.206\n",
            "[250] loss: 29.850\n",
            "[260] loss: 29.261\n",
            "[270] loss: 28.280\n",
            "[280] loss: 28.345\n",
            "[290] loss: 28.112\n",
            "[300] loss: 27.726\n",
            "[310] loss: 27.859\n",
            "[320] loss: 27.800\n",
            "[330] loss: 28.416\n",
            "[340] loss: 28.077\n",
            "[350] loss: 27.427\n",
            "[360] loss: 26.939\n",
            "[370] loss: 28.390\n",
            "[380] loss: 26.124\n",
            "[390] loss: 26.818\n",
            "[400] loss: 25.856\n",
            "[410] loss: 27.399\n",
            "[420] loss: 25.134\n",
            "[430] loss: 24.687\n",
            "[440] loss: 25.459\n",
            "[450] loss: 26.472\n",
            "[460] loss: 25.014\n",
            "[470] loss: 24.962\n",
            "[480] loss: 24.954\n",
            "[490] loss: 25.260\n",
            "[500] loss: 25.942\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27_n-djuEdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7991230e-82f6-487e-9ffb-9bb338c103d3"
      },
      "source": [
        "score = test(net, trainloader)\n",
        "print('Accuracy of the network on the train data: {}%'.format(score))\n",
        "score = test(net, testloader)\n",
        "print('Accuracy of the network on the test data: {}%'.format(score))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the train data: 96.1357990615512%\n",
            "Accuracy of the network on the test data: 92.22343921139102%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7l7yQEtNxh5"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQZoEjBSveV8"
      },
      "source": [
        "# Part 1: Visualize Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVWbC5YWT-MU"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# A convenience function which we use to copy CNNs\n",
        "def copy_model(model: nn.Module) -> nn.Module:\n",
        "    result = deepcopy(model)\n",
        "\n",
        "    # Copy over the extra metadata we've collected which copy.deepcopy doesn't capture\n",
        "    if hasattr(model, 'input_activations'):\n",
        "        result.input_activations = deepcopy(model.input_activations)\n",
        "\n",
        "    for result_layer, original_layer in zip(result.children(), model.children()):\n",
        "        if isinstance(result_layer, nn.Conv1d) or isinstance(result_layer, nn.Linear):\n",
        "            if hasattr(original_layer.weight, 'scale'):\n",
        "                result_layer.weight.scale = deepcopy(original_layer.weight.scale)\n",
        "            if hasattr(original_layer, 'activations'):\n",
        "                result_layer.activations = deepcopy(original_layer.activations)\n",
        "            if hasattr(original_layer, 'output_scale'):\n",
        "                result_layer.output_scale = deepcopy(original_layer.output_scale)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qKRX7ply7I2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2h7zJ8m3GAF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "10bc97a5-9c2c-459b-f4c8-674343c49d88"
      },
      "source": [
        "# ADD YOUR CODE HERE to plot distributions of weights\n",
        "\n",
        "# You can get a flattened vector of the weights of fc1 like this:\n",
        "#   fc1_weights = net.fc1.weight.data.cpu().view(-1)\n",
        "# Try plotting a histogram of fc1_weights (and the weights of all the other layers as well)\n",
        "\n",
        "def show_weight_dist(layer, title):\n",
        "  weights = layer.weight.data.cpu().view(-1)\n",
        "  plt.figure()\n",
        "  plt.hist(weights, 100)\n",
        "  plt.title(title)\n",
        "  min = weights.min()\n",
        "  max = weights.max()\n",
        "  mean = weights.mean()\n",
        "  std = weights.std()\n",
        "  plt.axvline(mean - 3*std)\n",
        "  plt.axvline(mean + 3*std)\n",
        "  print('{} min {:.03f}, max {:.03f}, mean'.format(title, min, max) +\n",
        "         ' {:.03f}, 3-sigma ({:.03f}, {:.03f})'.format(mean, mean - 3*std, mean + 3*std) +\n",
        "         ', max-min {:.03f}, 3-sigma range {:.03f}'.format(max - min, 6*std))\n",
        "\n",
        "show_weight_dist(net.conv1, 'conv1')\n",
        "show_weight_dist(net.conv2, 'conv2')\n",
        "show_weight_dist(net.fc1, 'fc1')\n",
        "\n",
        "# fc3 has a 3-sigma range that is greater than the max-min, would want to use\n",
        "# max-min as the range and not the 3-sigma one"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1 min -1.950, max 1.586, mean -0.014, 3-sigma (-0.924, 0.896), max-min 3.536, 3-sigma range 1.820\n",
            "conv2 min -0.893, max 1.423, mean -0.154, 3-sigma (-1.081, 0.773), max-min 2.315, 3-sigma range 1.854\n",
            "fc1 min -0.832, max 0.822, mean 0.001, 3-sigma (-0.615, 0.617), max-min 1.654, 3-sigma range 1.232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hKjshaHD11m"
      },
      "source": [
        "# Part 2: Quantize Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXNk1fXuPGjB"
      },
      "source": [
        "net_q2 = copy_model(net)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIBrqSFrVi5x"
      },
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def quantized_weights(weights: torch.Tensor) -> Tuple[torch.Tensor, float]:\n",
        "    '''\n",
        "    Quantize the weights so that all values are integers between -128 and 127.\n",
        "    You may want to use the total range, 3-sigma range, or some other range when\n",
        "    deciding just what factors to scale the float32 values by.\n",
        "\n",
        "    Parameters:\n",
        "    weights (Tensor): The unquantized weights\n",
        "\n",
        "    Returns:\n",
        "    (Tensor, float): A tuple with the following elements:\n",
        "                        * The weights in quantized form, where every value is an integer between -128 and 127.\n",
        "                          The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
        "                        * The scaling factor that your weights were multiplied by.\n",
        "                          This value does not need to be an 8-bit integer.\n",
        "    '''\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "    # std = weights.std()\n",
        "    absmax = weights.abs().max()\n",
        "    # scale = 127 / (3 * std)  # 3-sigma\n",
        "    scale = 127 / absmax\n",
        "    result = (weights * scale).round()\n",
        "    #return torch.clamp(result, min=-128, max=127), scale\n",
        "    return result, scale"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orOwTnXxU1nb"
      },
      "source": [
        "def quantize_layer_weights(model: nn.Module):\n",
        "    for layer in model.children():\n",
        "        if isinstance(layer, nn.Conv1d) or isinstance(layer, nn.Linear):\n",
        "            q_layer_data, scale = quantized_weights(layer.weight.cpu().data)\n",
        "            q_layer_data = q_layer_data.to(device)\n",
        "\n",
        "            layer.weight.data = q_layer_data\n",
        "            layer.weight.scale = scale\n",
        "\n",
        "            if (q_layer_data < -128).any() or (q_layer_data > 127).any():\n",
        "                raise Exception(\"Quantized weights of {} layer include values out of bounds for an 8-bit signed integer\".format(layer.__class__.__name__))\n",
        "            if (q_layer_data != q_layer_data.round()).any():\n",
        "                raise Exception(\"Quantized weights of {} layer include non-integer values\".format(layer.__class__.__name__))\n",
        "\n",
        "quantize_layer_weights(net_q2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE3HqeBKVoYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea6049a-afa7-498a-b9d6-c68a9a925dc6"
      },
      "source": [
        "score = test(net_q2, trainloader)\n",
        "print('Accuracy of the network after quantizing all weights (train): {}%'.format(score))\n",
        "score = test(net_q2, testloader)\n",
        "print('Accuracy of the network after quantizing all weights (test): {}%'.format(score))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network after quantizing all weights (train): 96.16340049682583%\n",
            "Accuracy of the network after quantizing all weights (test): 91.78532311062432%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsXmu8AZg41F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61e423c-2446-48ff-bb76-1d5746b57dba"
      },
      "source": [
        "net_q2.conv1.weight.data.cpu().numpy().min()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-127.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg7bfTF1bBVe"
      },
      "source": [
        "# Part 3: Visualize Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP587b0QYxe9"
      },
      "source": [
        "def register_activation_profiling_hooks(model: Net):\n",
        "    model.input_activations = np.empty(0)\n",
        "    model.conv1.activations = np.empty(0)\n",
        "    model.conv2.activations = np.empty(0)\n",
        "    model.fc1.activations = np.empty(0)\n",
        "\n",
        "    model.profile_activations = True\n",
        "\n",
        "    def conv1_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.input_activations = np.append(model.input_activations, x[0].cpu().flatten())\n",
        "    model.conv1.register_forward_hook(conv1_activations_hook)\n",
        "\n",
        "    def conv2_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.conv1.activations = np.append(model.conv1.activations, x[0].cpu().flatten())\n",
        "    model.conv2.register_forward_hook(conv2_activations_hook)\n",
        "\n",
        "    def fc1_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.conv2.activations = np.append(model.conv2.activations, x[0].cpu().flatten())\n",
        "            model.fc1.activations = np.append(model.fc1.activations, y[0].cpu().flatten())\n",
        "    model.fc1.register_forward_hook(fc1_activations_hook)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVvPCIoabLC7"
      },
      "source": [
        "net_q3 = copy_model(net)\n",
        "register_activation_profiling_hooks(net_q3)\n",
        "\n",
        "# Run through the training dataset again while profiling the input and output activations this time\n",
        "# We don't actually have to perform gradient descent for this, so we can use the \"test\" function\n",
        "test(net_q3, trainloader, max_samples=400)\n",
        "net_q3.profile_activations = False"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1HnYsuAMoxP"
      },
      "source": [
        "input_activations = net_q3.input_activations\n",
        "conv1_output_activations = net_q3.conv1.activations\n",
        "conv2_output_activations = net_q3.conv2.activations\n",
        "fc1_output_activations = net_q3.fc1.activations"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEo8VK46bwjn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cb53598b-ebc8-4b17-9f7c-e4a3dcfa57ae"
      },
      "source": [
        "# ADD YOUR CODE HERE to plot distributions of activations\n",
        "\n",
        "def show_weight_dist(data, title):\n",
        "    plt.figure()\n",
        "    plt.hist(data, 100)\n",
        "    plt.title(title)\n",
        "    min = data.min()\n",
        "    max = data.max()\n",
        "    mean = data.mean()\n",
        "    std = data.std()\n",
        "    #plt.axvline(mean - 3*std)\n",
        "    plt.axvline(mean + 3*std)\n",
        "    print('{} min {:.03f}, max {:.03f}, mean'.format(title, min, max) +\n",
        "          ' {:.03f}, 3-sigma ({:.03f}, {:.03f})'.format(mean, mean - 3*std, mean + 3*std) +\n",
        "          ', max-min {:.03f}, 3-sigma range {:.03f}'.format(max - min, 6*std))\n",
        "\n",
        "show_weight_dist(input_activations, 'input')\n",
        "show_weight_dist(conv1_output_activations, 'conv1')\n",
        "show_weight_dist(conv2_output_activations, 'conv2')\n",
        "show_weight_dist(fc1_output_activations, 'fc1')\n",
        "\n",
        "# Plot histograms of the following variables, and calculate their ranges and 3-sigma ranges:\n",
        "#   input_activations\n",
        "#   conv1_output_activations\n",
        "#   conv2_output_activations\n",
        "#   fc1_output_activations\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input min -5.670, max 6.084, mean 0.000, 3-sigma (-3.001, 3.001), max-min 11.753, 3-sigma range 6.002\n",
            "conv1 min 0.000, max 9.540, mean 0.962, 3-sigma (-2.880, 4.804), max-min 9.540, 3-sigma range 7.684\n",
            "conv2 min 0.000, max 6.728, mean 0.110, 3-sigma (-1.139, 1.359), max-min 6.728, 3-sigma range 2.498\n",
            "fc1 min -6.047, max 7.004, mean 0.012, 3-sigma (-9.879, 9.904), max-min 13.051, 3-sigma range 19.783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9PUHh4NjKc5"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haiPVx4ibEra"
      },
      "source": [
        "# Part 4: Quantize Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLjSp7hsXofq"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "class NetQuantized(nn.Module):\n",
        "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
        "        super(NetQuantized, self).__init__()\n",
        "        \n",
        "        net_init = copy_model(net_with_weights_quantized)\n",
        "\n",
        "        self.conv1 = net_init.conv1\n",
        "        self.pool = net_init.pool\n",
        "        self.conv2 = net_init.conv2\n",
        "        self.fc1 = net_init.fc1\n",
        "\n",
        "        for layer in self.conv1, self.conv2, self.fc1:\n",
        "            def pre_hook(l, x):\n",
        "                x = x[0]\n",
        "                if (x < -128).any() or (x > 127).any():\n",
        "                    raise Exception(\"Input to {} layer is out of bounds for an 8-bit signed integer\".format(l.__class__.__name__))\n",
        "                if (x != x.round()).any():\n",
        "                    raise Exception(\"Input to {} layer has non-integer values\".format(l.__class__.__name__))\n",
        "\n",
        "            layer.register_forward_pre_hook(pre_hook)\n",
        "\n",
        "        # Calculate the scaling factor for the initial input to the CNN\n",
        "        self.input_activations = net_with_weights_quantized.input_activations\n",
        "        self.input_scale = NetQuantized.quantize_initial_input(self.input_activations)\n",
        "\n",
        "        # Calculate the output scaling factors for all the layers of the CNN\n",
        "        preceding_layer_scales = []\n",
        "        for layer in self.conv1, self.conv2, self.fc1:\n",
        "            layer.output_scale = NetQuantized.quantize_activations(layer.activations, layer.weight.scale, self.input_scale, preceding_layer_scales)\n",
        "            preceding_layer_scales.append((layer.weight.scale, layer.output_scale))\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_initial_input(pixels: np.ndarray) -> float:\n",
        "        '''\n",
        "        Calculate a scaling factor for the images that are input to the first layer of the CNN.\n",
        "\n",
        "        Parameters:\n",
        "        pixels (ndarray): The values of all the pixels which were part of the input image during training\n",
        "\n",
        "        Returns:\n",
        "        float: A scaling factor that the input should be multiplied by before being fed into the first layer.\n",
        "               This value does not need to be an 8-bit integer.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        absmax = np.abs(pixels).max()\n",
        "        return 127 / absmax\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_activations(activations: np.ndarray, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> float:\n",
        "        '''\n",
        "        Calculate a scaling factor to multiply the output of a layer by.\n",
        "\n",
        "        Parameters:\n",
        "        activations (ndarray): The values of all the pixels which have been output by this layer during training\n",
        "        n_w (float): The scale by which the weights of this layer were multiplied as part of the \"quantize_weights\" function you wrote earlier\n",
        "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
        "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
        "\n",
        "        Returns:\n",
        "        float: A scaling factor that the layer output should be multiplied by before being fed into the first layer.\n",
        "               This value does not need to be an 8-bit integer.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        max = activations.max()\n",
        "        product = 1\n",
        "        for prev_scaling in ns:\n",
        "            product *= prev_scaling[0] * prev_scaling[1]\n",
        "        scale = 127 / (n_w * product * n_initial_input * max)  # return this for original output\n",
        "        return 2 ** np.floor(np.log2(scale))  # make scaling a power of 2!\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # You can access the output activation scales like this:\n",
        "        #   fc1_output_scale = self.fc1.output_scale\n",
        "\n",
        "        # To make sure that the outputs of each layer are integers between -128 and 127, you may need to use the following functions:\n",
        "        #   * torch.Tensor.round\n",
        "        #   * torch.clamp\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        x = x.reshape((x.shape[0], 50, 13)).transpose(1, 2)\n",
        "        x = torch.clamp(torch.round(x * self.input_scale), min=-128, max=127)\n",
        "        x = self.pool(torch.clamp(torch.floor(F.relu(self.conv1(x)) * self.conv1.output_scale), min=-128, max=127))\n",
        "        x = self.pool(torch.clamp(torch.floor(F.relu(self.conv2(x)) * self.conv2.output_scale), min=-128, max=127))\n",
        "        x = x.reshape((x.shape[0], 16*13))\n",
        "        #x = torch.clamp(torch.floor(self.fc1(x) * self.fc1.output_scale), min=-128, max=127)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CpHgvE994J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef362654-bc78-4f64-de33-ad5159caa58f"
      },
      "source": [
        "# Merge the information from net_q2 and net_q3 together\n",
        "net_init = copy_model(net_q2)\n",
        "net_init.input_activations = deepcopy(net_q3.input_activations)\n",
        "for layer_init, layer_q3 in zip(net_init.children(), net_q3.children()):\n",
        "    if isinstance(layer_init, nn.Conv1d) or isinstance(layer_init, nn.Linear):\n",
        "        layer_init.activations = deepcopy(layer_q3.activations)\n",
        "\n",
        "net_quantized = NetQuantized(net_init)\n",
        "\n",
        "for l in [net_quantized.conv1, net_quantized.conv2, net_quantized.fc1]:\n",
        "    print(np.log2(l.output_scale))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-7.)\n",
            "tensor(-6.)\n",
            "tensor(-7.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur6Rckyjy7tS",
        "outputId": "71907ee3-895d-4da2-8b76-a36659131ad8"
      },
      "source": [
        "score = test(net_quantized, trainloader)\n",
        "print('Accuracy of the network after quantizing activations (train): {}%'.format(score))\n",
        "score = test(net_quantized, testloader)\n",
        "print('Accuracy of the network after quantizing activations (test): {}%'.format(score))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network after quantizing all weights (train): 96.21860336737511%\n",
            "Accuracy of the network after quantizing all weights (test): 92.00438116100767%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpnyPRxzyNc8"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jTOL7scbMs7"
      },
      "source": [
        "# Part 5: Quantize Biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JI3f00ZdVKM"
      },
      "source": [
        "class NetWithBias(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetWithBias, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(13, 8, 3, padding=1, bias=True)\n",
        "        self.pool = nn.MaxPool1d(2, 2, ceil_mode=True)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.conv2 = nn.Conv1d(8, 16, 3, padding=1, bias=True)\n",
        "        self.fc1 = nn.Linear(16 * 13, 3, bias=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.reshape((x.shape[0], 50, 13)).transpose(1, 2)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = x.reshape((x.shape[0], 16*13))\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "net_with_bias = NetWithBias().to(device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjk3hEQaVDpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837c35a4-7110-460b-b47a-504e8530940f"
      },
      "source": [
        "train(net_with_bias, trainloader)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10] loss: 126.443\n",
            "[20] loss: 106.172\n",
            "[30] loss: 89.175\n",
            "[40] loss: 80.771\n",
            "[50] loss: 72.018\n",
            "[60] loss: 62.697\n",
            "[70] loss: 55.255\n",
            "[80] loss: 48.167\n",
            "[90] loss: 45.020\n",
            "[100] loss: 42.944\n",
            "[110] loss: 39.401\n",
            "[120] loss: 36.430\n",
            "[130] loss: 35.194\n",
            "[140] loss: 34.104\n",
            "[150] loss: 32.663\n",
            "[160] loss: 32.012\n",
            "[170] loss: 32.102\n",
            "[180] loss: 30.419\n",
            "[190] loss: 30.162\n",
            "[200] loss: 26.605\n",
            "[210] loss: 29.479\n",
            "[220] loss: 28.163\n",
            "[230] loss: 28.205\n",
            "[240] loss: 29.480\n",
            "[250] loss: 28.298\n",
            "[260] loss: 25.609\n",
            "[270] loss: 27.199\n",
            "[280] loss: 26.343\n",
            "[290] loss: 26.377\n",
            "[300] loss: 25.239\n",
            "[310] loss: 26.092\n",
            "[320] loss: 25.521\n",
            "[330] loss: 25.459\n",
            "[340] loss: 26.000\n",
            "[350] loss: 24.440\n",
            "[360] loss: 26.126\n",
            "[370] loss: 24.146\n",
            "[380] loss: 23.832\n",
            "[390] loss: 25.736\n",
            "[400] loss: 24.026\n",
            "[410] loss: 22.561\n",
            "[420] loss: 23.497\n",
            "[430] loss: 24.554\n",
            "[440] loss: 23.824\n",
            "[450] loss: 23.278\n",
            "[460] loss: 22.920\n",
            "[470] loss: 23.491\n",
            "[480] loss: 24.620\n",
            "[490] loss: 23.988\n",
            "[500] loss: 22.573\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9ohsZVmdpGm",
        "outputId": "20a56288-97ab-407b-9225-bf6fd5f5ca05"
      },
      "source": [
        "score = test(net_with_bias, trainloader)\n",
        "print('Accuracy of the network with bias (train): {}%'.format(score))\n",
        "score = test(net_with_bias, testloader)\n",
        "print('Accuracy of the network with bias (test): {}%'.format(score))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network with bias (train): 96.16340049682583%\n",
            "Accuracy of the network with bias (test): 92.66155531215772%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ZiJk6yEEM-"
      },
      "source": [
        "register_activation_profiling_hooks(net_with_bias)\n",
        "test(net_with_bias, trainloader, max_samples=400)\n",
        "net_with_bias.profile_activations = False"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZwk8KLtAUAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44492ced-c5fc-4838-8c77-cafd58c351b0"
      },
      "source": [
        "net_with_bias_with_quantized_weights = copy_model(net_with_bias)\n",
        "quantize_layer_weights(net_with_bias_with_quantized_weights)\n",
        "\n",
        "score = test(net_with_bias_with_quantized_weights, trainloader)\n",
        "print('Accuracy of the network on the train images after all the weights are quantized but the bias isn\\'t: {}%'.format(score))\n",
        "score = test(net_with_bias_with_quantized_weights, testloader)\n",
        "print('Accuracy of the network on the test images after all the weights are quantized but the bias isn\\'t: {}%'.format(score))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the train images after all the weights are quantized but the bias isn't: 54.98205906707149%\n",
            "Accuracy of the network on the test images after all the weights are quantized but the bias isn't: 55.75027382256298%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO2Gdu_tEZ4v"
      },
      "source": [
        "class NetQuantizedWithBias(NetQuantized):\n",
        "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
        "        super(NetQuantizedWithBias, self).__init__(net_with_weights_quantized)\n",
        "\n",
        "\n",
        "        for i, l in enumerate([self.conv1, self.conv2, self.fc1]):\n",
        "            preceding_scales = [(layer.weight.scale, layer.output_scale) for layer in self.children() if isinstance(layer, nn.Conv1d) or isinstance(layer, nn.Linear)][:i]\n",
        "\n",
        "            l.bias.data = NetQuantizedWithBias.quantized_bias(\n",
        "                l.bias.data,\n",
        "                l.weight.scale,\n",
        "                self.input_scale,\n",
        "                preceding_scales\n",
        "            )\n",
        "\n",
        "            if (l.bias.data < -2147483648).any() or (l.bias.data > 2147483647).any():\n",
        "                raise Exception(\"Bias has values which are out of bounds for an 32-bit signed integer\")\n",
        "            if (l.bias.data != l.bias.data.round()).any():\n",
        "                raise Exception(\"Bias has non-integer values\")\n",
        "\n",
        "    @staticmethod\n",
        "    def quantized_bias(bias: torch.Tensor, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> torch.Tensor:\n",
        "        '''\n",
        "        Quantize the bias so that all values are integers between -2147483648 and 2147483647.\n",
        "\n",
        "        Parameters:\n",
        "        bias (Tensor): The floating point values of the bias\n",
        "        n_w (float): The scale by which the weights of this layer were multiplied\n",
        "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
        "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The bias in quantized form, where every value is an integer between -2147483648 and 2147483647.\n",
        "                The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        product = 1\n",
        "        for prev_scaling in ns:\n",
        "            product *= prev_scaling[0] * prev_scaling[1]\n",
        "        scale = (n_w * product * n_initial_input)\n",
        "        return (bias * scale).round()\n",
        "        #return torch.clamp((bias * 2.5).round(), min=-2147483648, max=2147483647)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA6rXt3Q-zF8"
      },
      "source": [
        "net_quantized_with_bias = NetQuantizedWithBias(net_with_bias_with_quantized_weights)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9ho_iCwfVoG",
        "outputId": "5443092c-599a-4b0c-eba7-430e1ecb850e"
      },
      "source": [
        "score = test(net_quantized_with_bias, trainloader)\n",
        "print('Accuracy of the network with quantized weights and bias (train): {}%'.format(score))\n",
        "score = test(net_quantized_with_bias, testloader)\n",
        "print('Accuracy of the network with quantized weights and bias (test): {}%'.format(score))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network with quantized weights and bias (train): 96.0529947557273%\n",
            "Accuracy of the network with quantized weights and bias (test): 92.7710843373494%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ga8xxxLhrc_",
        "outputId": "da35a418-71ed-4b75-fbf2-6a3fbf658187"
      },
      "source": [
        "print('Number of parameters in each layer:')\n",
        "for p in net_quantized_with_bias.parameters():\n",
        "    print(p.numel())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters in each layer:\n",
            "312\n",
            "8\n",
            "384\n",
            "16\n",
            "624\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDriUNRThyQF"
      },
      "source": [
        "# Part 6: Numpy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgbtLHSRh3Pd"
      },
      "source": [
        "conv1_weights = net_quantized_with_bias.conv1.weight.data.cpu().numpy().astype(np.int8)\n",
        "conv1_biases = net_quantized_with_bias.conv1.bias.data.cpu().numpy().astype(np.int32)\n",
        "conv2_weights = net_quantized_with_bias.conv2.weight.data.cpu().numpy().astype(np.int8)\n",
        "conv2_biases = net_quantized_with_bias.conv2.bias.data.cpu().numpy().astype(np.int32)\n",
        "fc1_weights = net_quantized_with_bias.fc1.weight.data.cpu().numpy().astype(np.int8)\n",
        "fc1_biases = net_quantized_with_bias.fc1.bias.data.cpu().numpy().astype(np.int32)\n",
        "\n",
        "# transpose the weights so that they match the numpy model\n",
        "conv1_weights = np.transpose(conv1_weights, (2, 1, 0))\n",
        "conv2_weights = np.transpose(conv2_weights, (2, 1, 0))\n",
        "#fc1_weights = np.transpose(fc1_weights, (1, 0))  # works if x is transposed\n",
        "fc1_weights = np.transpose(fc1_weights.reshape(3, 16, 13), (0, 2, 1)).reshape(3, 208).T\n",
        "\n",
        "# get the featuremap scalings\n",
        "input_scale = net_quantized_with_bias.input_scale\n",
        "conv1_output_scale = net_quantized_with_bias.conv1.output_scale\n",
        "conv2_output_scale = net_quantized_with_bias.conv2.output_scale\n",
        "fc1_output_scale = net_quantized_with_bias.fc1.output_scale\n",
        "\n",
        "# bitshifts is the amount that each featuremap is shifted to the right eg: 8 would be a divide by 256\n",
        "bitshifts = -np.log2(np.array([conv1_output_scale, conv2_output_scale, fc1_output_scale])).astype(np.int8)\n",
        "\n",
        "input_scale_arr = np.array(input_scale)  # single element array for input featuremap scaling\n",
        "\n",
        "weights_list = [input_scale_arr, bitshifts,\n",
        "                conv1_weights, conv1_biases,\n",
        "                conv2_weights, conv2_biases,\n",
        "                fc1_weights, fc1_biases]\n",
        "np.savez('parameters_quantized.npz', *weights_list)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIeMZLeW7Fer",
        "outputId": "0ea96a65-20ba-4ae8-f29c-05d9c7e2e597"
      },
      "source": [
        "weights_archive = np.load('parameters_quantized.npz')\n",
        "weights_list = [weights_archive['arr_{}'.format(i)] for i in range(len(weights_archive))]\n",
        "\n",
        "for weights in weights_list:\n",
        "    print(weights.shape)\n",
        "\n",
        "input_scale = weights_list[0]\n",
        "bitshifts = weights_list[1]\n",
        "conv1_weights = weights_list[2]\n",
        "conv1_biases = weights_list[3]\n",
        "conv2_weights = weights_list[4]\n",
        "conv2_biases = weights_list[5]\n",
        "fc1_weights = weights_list[6]\n",
        "fc1_biases = weights_list[7]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "()\n",
            "(3,)\n",
            "(3, 13, 8)\n",
            "(8,)\n",
            "(3, 8, 16)\n",
            "(16,)\n",
            "(208, 3)\n",
            "(3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyl-WV3OiRpP"
      },
      "source": [
        "def relu(x):\n",
        "    return np.maximum(x, 0)\n",
        "\n",
        "def conv1d_single_kernel(x, weights, bias):\n",
        "    '''Perform convolution of a input feature map with a single filter and bias.\n",
        "    \n",
        "    featuremap dims are (time, n_coeffs), so (50, 13)\n",
        "    '''\n",
        "    out = np.zeros(x.shape[0], dtype=np.int64)  # output length is the same\n",
        "    x_pad = np.zeros((x.shape[0]+2, x.shape[1]), dtype=np.int64)\n",
        "    x_pad[1:-1,:] = x  # zero padding\n",
        "    for i in range(x.shape[0]):\n",
        "        section = x_pad[i:i+3,:]\n",
        "        out[i] = relu(np.sum(section * weights) + bias)\n",
        "    return out\n",
        "\n",
        "def conv1d_multi_kernel(x, weights, biases):\n",
        "    n_kernels = weights.shape[2]\n",
        "    out = np.zeros((x.shape[0], n_kernels), dtype=np.int64)\n",
        "    for i in range(n_kernels):\n",
        "        kernel = weights[:,:,i]\n",
        "        out[:,i] = conv1d_single_kernel(x, kernel, biases[i])\n",
        "    return out\n",
        "\n",
        "def max_pool_1d(x):\n",
        "    out = np.zeros((int(np.ceil(x.shape[0] / 2)), x.shape[1]), dtype=np.int8)\n",
        "    for j in range(x.shape[1]):\n",
        "        for i in range(int(np.floor(x.shape[0] / 2))):\n",
        "            out[i, j] = np.maximum(x[2*i, j], x[2*i+1, j])\n",
        "        if (x.shape[0] % 2 == 1):\n",
        "            out[-1, j] = x[-1, j]\n",
        "    return out\n",
        "\n",
        "def fc(x, weights, biases):\n",
        "    x = x.flatten()\n",
        "    out = np.matmul(x, weights, dtype=np.int64) + biases\n",
        "    return out\n",
        "\n",
        "def scale_feature_map(x, shift):\n",
        "    '''Scale a featuremap to a byte range given the amount to right shift by.\n",
        "\n",
        "    Since all weight, bias, and activation quantizations are mapped using the full range\n",
        "    of values, there is not any need for clamping the values to the range [-128, 127].\n",
        "    However, it is still useful since the quantization could be changed to not map to the\n",
        "    full range of the unquantized values.\n",
        "    '''\n",
        "    x = np.right_shift(x, shift)\n",
        "    x = np.clip(x, -128, 127)\n",
        "    x = x.astype(np.int8)\n",
        "    return x\n",
        "\n",
        "def get_numpy_pred(features):\n",
        "    out = np.zeros((features.shape[0], 3), dtype=np.int64)\n",
        "    for i in range(features.shape[0]):\n",
        "        # condition input feature map\n",
        "        x = features[i]\n",
        "        x = x.reshape((int(x.size / 13), 13))\n",
        "        x = np.clip(np.round(x * input_scale), -128, 127).astype(np.int8)\n",
        "\n",
        "        # conv1\n",
        "        x = conv1d_multi_kernel(x, conv1_weights, conv1_biases)\n",
        "        x = scale_feature_map(x, bitshifts[0])\n",
        "        x = max_pool_1d(x)\n",
        "\n",
        "        # conv2\n",
        "        x = conv1d_multi_kernel(x, conv2_weights, conv2_biases)\n",
        "        x = scale_feature_map(x, bitshifts[1])\n",
        "        x = max_pool_1d(x)\n",
        "\n",
        "        # fc1\n",
        "        x = fc(x, fc1_weights, fc1_biases)\n",
        "        \n",
        "        out[i] = x\n",
        "    return out"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxDv67ZHvR3n",
        "outputId": "6e36d3a4-e56b-4b7f-c7d6-6b339645f3e2"
      },
      "source": [
        "numpy_pred = get_numpy_pred(X[:1,:])\n",
        "numpy_pred.shape"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkgYmJvV7_Fa",
        "outputId": "522b7e15-af23-4275-8c04-9f6597bb3b45"
      },
      "source": [
        "def get_torch_pred(input):\n",
        "    return net_quantized_with_bias.forward(torch.tensor(input, device=device)).detach().cpu().numpy()\n",
        "\n",
        "torch_pred = get_torch_pred(X[:1,:])\n",
        "torch_pred.shape"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQPCZMWDRTGi",
        "outputId": "319da265-3453-44a7-ed87-00c419186c27"
      },
      "source": [
        "numpy_pred - torch_pred"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr6r5V359-4s",
        "outputId": "07f3c2b5-a2ce-405a-87f8-0ac8cd31843c"
      },
      "source": [
        "# compare output for each sample in test data\n",
        "\n",
        "n_err = 0\n",
        "for i in range(Xtest.shape[0]):\n",
        "    numpy_pred = get_numpy_pred(X[i:i+1, :])\n",
        "    torch_pred = get_torch_pred(X[i:i+1, :])\n",
        "    diff = numpy_pred - torch_pred\n",
        "    if np.abs(diff).max() > 1e-9:\n",
        "        n_err += 1\n",
        "        print('Difference between outputs at sample ', i)\n",
        "    if n_err > 10:\n",
        "        break\n",
        "\n",
        "print('No differences between numpy model and torch model!')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No differences between numpy model and torch model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Tsq1QbEyqA"
      },
      "source": [
        ""
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yXTLUELLMex"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}