{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WakeyWakeyNNArch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuhU8wRTOAQW"
      },
      "source": [
        "# Featurization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_WLB-Rm1xMJ",
        "outputId": "bae19922-c2bf-4193-a47b-9b010d70e506"
      },
      "source": [
        "import os\n",
        "# download and unzip keywords dataset\n",
        "os.system('curl -O https://cdn.edgeimpulse.com/datasets/keywords2.zip')\n",
        "os.system('unzip keywords2.zip')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pGkHIn21x8Q",
        "outputId": "2eeb9017-9f36-4835-b45b-0147dcdb9440"
      },
      "source": [
        "!pip install speechpy\n",
        "import speechpy\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "\n",
        "train_test_split = 0.75  # fraction to have as training data\n",
        "\n",
        "p = {'num_mfcc_cof': 13,\n",
        "     'frame_length': 0.02,\n",
        "     'frame_stride': 0.02,\n",
        "     'filter_num': 32,\n",
        "     'fft_length': 256,\n",
        "     'window_size': 101,\n",
        "     'low_frequency': 300,\n",
        "     'preemph_cof': 0.98}\n",
        "\n",
        "def get_features(fullfname):\n",
        "    try:\n",
        "        fs, data = wavfile.read(fullfname)\n",
        "    except ValueError:\n",
        "        print('failed to read file {}, continuing'.format(fullfname))\n",
        "        return np.zeros(650)\n",
        "\n",
        "    # generate features\n",
        "    preemphasized = speechpy.processing.preemphasis(data, cof=p['preemph_cof'], shift=1)\n",
        "    mfcc = speechpy.feature.mfcc(preemphasized, fs, frame_length=p['frame_length'],\n",
        "                                  frame_stride=p['frame_stride'], num_cepstral=p['num_mfcc_cof'],\n",
        "                                  num_filters=p['filter_num'], fft_length=p['fft_length'],\n",
        "                                  low_frequency=p['low_frequency'])\n",
        "    #print('mfcc shape', mfcc.shape)\n",
        "    # TODO: Why is the output shape here (49, 13) and not (50, 13)?\n",
        "    # For now just repeat last frame:\n",
        "    mfcc2 = np.zeros((50, 13))\n",
        "    mfcc2[:-1,:] = mfcc\n",
        "    mfcc2[-1,:] = mfcc[-1,:]\n",
        "    \n",
        "    mfcc_cmvn = speechpy.processing.cmvnw(mfcc2, win_size=p['window_size'], variance_normalization=True)\n",
        "\n",
        "    flattened = mfcc_cmvn.flatten()\n",
        "    return flattened\n",
        "  \n",
        "def get_fnames(group):\n",
        "    dir = group + '/'\n",
        "    fnames = os.listdir(dir)\n",
        "    fnames = [x for x in fnames if not x.startswith('.')]  # ignore .DS_Store\n",
        "    fullnames = [dir + fname for fname in fnames]\n",
        "    return fullnames\n",
        "    \n",
        "# collect a big list of filenames and a big list of labels\n",
        "all_fnames = []\n",
        "all_labels = []\n",
        "for group in ['yes', 'unknown', 'noise']:\n",
        "    fnames = get_fnames(group)\n",
        "    label = 1 if group == 'yes' else 2\n",
        "    repeat = 2 if group == 'yes' else 1  # oversample wake word class to balance dataset\n",
        "    for _ in range(repeat):\n",
        "        all_fnames.extend(fnames)\n",
        "        for i in range(len(fnames)):\n",
        "            all_labels.append(label)\n",
        "    \n",
        "# get a big list of mfcc features\n",
        "n = len(all_fnames)\n",
        "print('num samples: ', n)\n",
        "all_features = np.zeros((0, 13*50))\n",
        "for fname in all_fnames:\n",
        "    features = get_features(fname)\n",
        "    all_features = np.vstack((all_features, features))\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# shuffle the data randomly\n",
        "idx = np.arange(n, dtype=int)\n",
        "np.random.shuffle(idx)\n",
        "features_shuffled = all_features[idx,:]\n",
        "labels_shuffled = all_labels[idx]\n",
        "\n",
        "# split the data into train and test sets\n",
        "split = int(0.75 * n)\n",
        "X = features_shuffled[:split,:]\n",
        "Y = labels_shuffled[:split]\n",
        "Xtest = features_shuffled[split:,:]\n",
        "Ytest = labels_shuffled[split:]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: speechpy in /usr/local/lib/python3.7/dist-packages (2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechpy) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechpy) (1.19.5)\n",
            "num samples:  6036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "OPi-1yClDQAY",
        "outputId": "4361530c-258a-4e27-dca6-6463f02eab04"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the dataset balance\n",
        "\n",
        "def plot_dist(labels, title):\n",
        "    plt.figure()\n",
        "    nl = len(np.unique(labels))\n",
        "    freqs = np.zeros(nl)\n",
        "    for label in Y:\n",
        "        freqs[label-1] += 1\n",
        "    plt.bar(np.arange(nl)+1, freqs)\n",
        "    plt.title(title)\n",
        "\n",
        "plot_dist(Y, 'Training dataset balance')\n",
        "plot_dist(Ytest, 'Testing dataset balance')\n",
        "\n",
        "yes_features = X[Y==1,:]\n",
        "unknown_features = X[Y!=1,:]\n",
        "\n",
        "def plot_samples():\n",
        "    # plot some samples\n",
        "    for i in range(5):\n",
        "        plt.figure()\n",
        "        plt.subplot(121)\n",
        "        plt.imshow(yes_features[i,:].reshape(50, 13).T)\n",
        "        plt.title('Yes sample')\n",
        "        plt.subplot(122)\n",
        "        plt.imshow(unknown_features[i,:].reshape(50, 13).T)\n",
        "        plt.title('Unknown sample')\n",
        "  \n",
        "def plot_average_sample():\n",
        "    # plot the average yes and unknown sample\n",
        "    avg_yes = np.zeros(50, 13)\n",
        "    avg_unknown = np.zeros(50, 13)\n",
        "    for i in range(len(yes_features)):\n",
        "        avg_yes += yes_features[i,:].reshape(50, 13)\n",
        "    for i in range(len(unknown_features)):\n",
        "        avg_yes += unknown_features[i,:].reshape(50, 13)\n",
        "    avg_yes / len(yes_features)\n",
        "    avg_unknown / len(unknown_features)\n",
        "    plt.figure()\n",
        "    plt.imshow(avg_yes.T)\n",
        "    plt.title('average yes')\n",
        "    plt.figure()\n",
        "    plt.imshow(avg_unknown.T)\n",
        "    plt.title('average unknown')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbiiMcdNJI--"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3RF5VmcoUMG"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fL3F-7Rntog"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(13, 8, 3, padding=1, bias=False)\n",
        "        self.pool = nn.MaxPool1d(2, 2, ceil_mode=True)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.conv2 = nn.Conv1d(8, 16, 3, padding=1, bias=False)\n",
        "        self.fc1 = nn.Linear(16 * 13, 2, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.reshape((x.shape[0], 50, 13)).transpose(1, 2)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = x.reshape((x.shape[0], 16*13))\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzK6ohj5oNCT"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 500\n",
        "\n",
        "Y_tensor = torch.Tensor(Y-1).type(torch.int64)\n",
        "trainset = TensorDataset(torch.Tensor(X), Y_tensor)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "\n",
        "Ytest_tensor = torch.Tensor(Ytest-1).type(torch.int64)\n",
        "testset = TensorDataset(torch.Tensor(Xtest), Ytest_tensor)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)\n",
        "\n",
        "def train(model: nn.Module, dataloader: DataLoader):\n",
        "    model.train()  # turn on dropout layers\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        #for i in range(len(X)):\n",
        "        #    inputs = torch.tensor(X[i,:]).reshape((1, 650))\n",
        "        #    labels = torch.tensor(Y[i] - 1, dtype=torch.int64).reshape(1)\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "        if epoch % 10 == 9:\n",
        "            print('[%d] loss: %.3f' % (epoch + 1, running_loss))\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "def test(model: nn.Module, dataloader: DataLoader, max_samples=None) -> float:\n",
        "    model.eval()  # turn off dropout layers\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    n_inferences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #for i in range(len(X)):\n",
        "        #    inputs = torch.tensor(X[i,:]).reshape((1, 650))\n",
        "        #    labels = torch.tensor(Y[i]).reshape(1)\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if max_samples:\n",
        "                n_inferences += inputs.shape[0]\n",
        "                if n_inferences > max_samples:\n",
        "                    break\n",
        "    \n",
        "    return 100 * correct / total"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HixhBHaqtmZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a917a07-23b6-4742-f313-c6c5e5d61ae0"
      },
      "source": [
        "train(net, trainloader)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10] loss: 55.281\n",
            "[20] loss: 33.340\n",
            "[30] loss: 27.119\n",
            "[40] loss: 23.348\n",
            "[50] loss: 21.832\n",
            "[60] loss: 21.010\n",
            "[70] loss: 19.390\n",
            "[80] loss: 18.650\n",
            "[90] loss: 17.446\n",
            "[100] loss: 16.648\n",
            "[110] loss: 16.960\n",
            "[120] loss: 15.435\n",
            "[130] loss: 15.923\n",
            "[140] loss: 16.592\n",
            "[150] loss: 14.888\n",
            "[160] loss: 14.890\n",
            "[170] loss: 14.481\n",
            "[180] loss: 13.230\n",
            "[190] loss: 13.922\n",
            "[200] loss: 13.670\n",
            "[210] loss: 15.044\n",
            "[220] loss: 13.878\n",
            "[230] loss: 12.745\n",
            "[240] loss: 13.326\n",
            "[250] loss: 14.807\n",
            "[260] loss: 12.513\n",
            "[270] loss: 12.994\n",
            "[280] loss: 13.098\n",
            "[290] loss: 12.551\n",
            "[300] loss: 12.822\n",
            "[310] loss: 12.889\n",
            "[320] loss: 11.980\n",
            "[330] loss: 12.321\n",
            "[340] loss: 12.723\n",
            "[350] loss: 11.834\n",
            "[360] loss: 12.211\n",
            "[370] loss: 11.663\n",
            "[380] loss: 12.456\n",
            "[390] loss: 13.104\n",
            "[400] loss: 11.821\n",
            "[410] loss: 12.400\n",
            "[420] loss: 11.814\n",
            "[430] loss: 11.421\n",
            "[440] loss: 11.552\n",
            "[450] loss: 11.878\n",
            "[460] loss: 11.108\n",
            "[470] loss: 11.145\n",
            "[480] loss: 10.749\n",
            "[490] loss: 10.790\n",
            "[500] loss: 11.277\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y27_n-djuEdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030587e7-e562-4ccf-ffde-27248fbdd221"
      },
      "source": [
        "score = test(net, trainloader)\n",
        "print('Accuracy of the network on the train data: {}%'.format(score))\n",
        "score = test(net, testloader)\n",
        "print('Accuracy of the network on the test data: {}%'.format(score))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the train data: 98.80715705765408%\n",
            "Accuracy of the network on the test data: 97.6805831676607%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7l7yQEtNxh5"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQZoEjBSveV8"
      },
      "source": [
        "# Part 1: Visualize Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVWbC5YWT-MU"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# A convenience function which we use to copy CNNs\n",
        "def copy_model(model: nn.Module) -> nn.Module:\n",
        "    result = deepcopy(model)\n",
        "\n",
        "    # Copy over the extra metadata we've collected which copy.deepcopy doesn't capture\n",
        "    if hasattr(model, 'input_activations'):\n",
        "        result.input_activations = deepcopy(model.input_activations)\n",
        "\n",
        "    for result_layer, original_layer in zip(result.children(), model.children()):\n",
        "        if isinstance(result_layer, nn.Conv1d) or isinstance(result_layer, nn.Linear):\n",
        "            if hasattr(original_layer.weight, 'scale'):\n",
        "                result_layer.weight.scale = deepcopy(original_layer.weight.scale)\n",
        "            if hasattr(original_layer, 'activations'):\n",
        "                result_layer.activations = deepcopy(original_layer.activations)\n",
        "            if hasattr(original_layer, 'output_scale'):\n",
        "                result_layer.output_scale = deepcopy(original_layer.output_scale)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qKRX7ply7I2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2h7zJ8m3GAF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "34af19b5-6c44-432d-903d-df9d09491977"
      },
      "source": [
        "# ADD YOUR CODE HERE to plot distributions of weights\n",
        "\n",
        "# You can get a flattened vector of the weights of fc1 like this:\n",
        "#   fc1_weights = net.fc1.weight.data.cpu().view(-1)\n",
        "# Try plotting a histogram of fc1_weights (and the weights of all the other layers as well)\n",
        "\n",
        "def show_weight_dist(layer, title):\n",
        "  weights = layer.weight.data.cpu().view(-1)\n",
        "  plt.figure()\n",
        "  plt.hist(weights, 100)\n",
        "  plt.title(title)\n",
        "  min = weights.min()\n",
        "  max = weights.max()\n",
        "  mean = weights.mean()\n",
        "  std = weights.std()\n",
        "  plt.axvline(mean - 3*std)\n",
        "  plt.axvline(mean + 3*std)\n",
        "  print('{} min {:.03f}, max {:.03f}, mean'.format(title, min, max) +\n",
        "         ' {:.03f}, 3-sigma ({:.03f}, {:.03f})'.format(mean, mean - 3*std, mean + 3*std) +\n",
        "         ', max-min {:.03f}, 3-sigma range {:.03f}'.format(max - min, 6*std))\n",
        "\n",
        "show_weight_dist(net.conv1, 'conv1')\n",
        "show_weight_dist(net.conv2, 'conv2')\n",
        "show_weight_dist(net.fc1, 'fc1')\n",
        "\n",
        "# fc3 has a 3-sigma range that is greater than the max-min, would want to use\n",
        "# max-min as the range and not the 3-sigma one"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1 min -1.103, max 1.015, mean -0.003, 3-sigma (-0.723, 0.717), max-min 2.118, 3-sigma range 1.440\n",
            "conv2 min -0.651, max 0.755, mean -0.084, 3-sigma (-0.744, 0.576), max-min 1.407, 3-sigma range 1.320\n",
            "fc1 min -0.433, max 0.396, mean 0.003, 3-sigma (-0.553, 0.558), max-min 0.828, 3-sigma range 1.112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hKjshaHD11m"
      },
      "source": [
        "# Part 2: Quantize Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXNk1fXuPGjB"
      },
      "source": [
        "net_q2 = copy_model(net)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIBrqSFrVi5x"
      },
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def quantized_weights(weights: torch.Tensor) -> Tuple[torch.Tensor, float]:\n",
        "    '''\n",
        "    Quantize the weights so that all values are integers between -128 and 127.\n",
        "    You may want to use the total range, 3-sigma range, or some other range when\n",
        "    deciding just what factors to scale the float32 values by.\n",
        "\n",
        "    Parameters:\n",
        "    weights (Tensor): The unquantized weights\n",
        "\n",
        "    Returns:\n",
        "    (Tensor, float): A tuple with the following elements:\n",
        "                        * The weights in quantized form, where every value is an integer between -128 and 127.\n",
        "                          The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
        "                        * The scaling factor that your weights were multiplied by.\n",
        "                          This value does not need to be an 8-bit integer.\n",
        "    '''\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "    # std = weights.std()\n",
        "    absmax = weights.abs().max()\n",
        "    # scale = 127 / (3 * std)  # 3-sigma\n",
        "    scale = 127 / absmax\n",
        "    result = (weights * scale).round()\n",
        "    #return torch.clamp(result, min=-128, max=127), scale\n",
        "    return result, scale"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orOwTnXxU1nb"
      },
      "source": [
        "def quantize_layer_weights(model: nn.Module):\n",
        "    for layer in model.children():\n",
        "        if isinstance(layer, nn.Conv1d) or isinstance(layer, nn.Linear):\n",
        "            q_layer_data, scale = quantized_weights(layer.weight.cpu().data)\n",
        "            q_layer_data = q_layer_data.to(device)\n",
        "\n",
        "            layer.weight.data = q_layer_data\n",
        "            layer.weight.scale = scale\n",
        "\n",
        "            if (q_layer_data < -128).any() or (q_layer_data > 127).any():\n",
        "                raise Exception(\"Quantized weights of {} layer include values out of bounds for an 8-bit signed integer\".format(layer.__class__.__name__))\n",
        "            if (q_layer_data != q_layer_data.round()).any():\n",
        "                raise Exception(\"Quantized weights of {} layer include non-integer values\".format(layer.__class__.__name__))\n",
        "\n",
        "quantize_layer_weights(net_q2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE3HqeBKVoYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2bf11b-e12e-4e69-b334-24ee7dede2b8"
      },
      "source": [
        "score = test(net_q2, trainloader)\n",
        "print('Accuracy of the network after quantizing all weights (train): {}%'.format(score))\n",
        "score = test(net_q2, testloader)\n",
        "print('Accuracy of the network after quantizing all weights (test): {}%'.format(score))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network after quantizing all weights (train): 98.78506737353656%\n",
            "Accuracy of the network after quantizing all weights (test): 97.6805831676607%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsXmu8AZg41F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b435f8d-8d70-429b-e0d4-8e929b77491e"
      },
      "source": [
        "net_q2.conv1.weight.data.cpu().numpy().min()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-127.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg7bfTF1bBVe"
      },
      "source": [
        "# Part 3: Visualize Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP587b0QYxe9"
      },
      "source": [
        "def register_activation_profiling_hooks(model: Net):\n",
        "    model.input_activations = np.empty(0)\n",
        "    model.conv1.activations = np.empty(0)\n",
        "    model.conv2.activations = np.empty(0)\n",
        "    model.fc1.activations = np.empty(0)\n",
        "\n",
        "    model.profile_activations = True\n",
        "\n",
        "    def conv1_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.input_activations = np.append(model.input_activations, x[0].cpu().flatten())\n",
        "    model.conv1.register_forward_hook(conv1_activations_hook)\n",
        "\n",
        "    def conv2_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.conv1.activations = np.append(model.conv1.activations, x[0].cpu().flatten())\n",
        "    model.conv2.register_forward_hook(conv2_activations_hook)\n",
        "\n",
        "    def fc1_activations_hook(layer, x, y):\n",
        "        if model.profile_activations:\n",
        "            model.conv2.activations = np.append(model.conv2.activations, x[0].cpu().flatten())\n",
        "            model.fc1.activations = np.append(model.fc1.activations, y[0].cpu().flatten())\n",
        "    model.fc1.register_forward_hook(fc1_activations_hook)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVvPCIoabLC7"
      },
      "source": [
        "net_q3 = copy_model(net)\n",
        "register_activation_profiling_hooks(net_q3)\n",
        "\n",
        "# Run through the training dataset again while profiling the input and output activations this time\n",
        "# We don't actually have to perform gradient descent for this, so we can use the \"test\" function\n",
        "test(net_q3, trainloader, max_samples=400)\n",
        "net_q3.profile_activations = False"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1HnYsuAMoxP"
      },
      "source": [
        "input_activations = net_q3.input_activations\n",
        "conv1_output_activations = net_q3.conv1.activations\n",
        "conv2_output_activations = net_q3.conv2.activations\n",
        "fc1_output_activations = net_q3.fc1.activations"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEo8VK46bwjn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a2cbd3a-a0b0-4f6c-a2bf-e7b7dbfde41e"
      },
      "source": [
        "# ADD YOUR CODE HERE to plot distributions of activations\n",
        "\n",
        "def show_weight_dist(data, title):\n",
        "    plt.figure()\n",
        "    plt.hist(data, 100)\n",
        "    plt.title(title)\n",
        "    min = data.min()\n",
        "    max = data.max()\n",
        "    mean = data.mean()\n",
        "    std = data.std()\n",
        "    #plt.axvline(mean - 3*std)\n",
        "    plt.axvline(mean + 3*std)\n",
        "    print('{} min {:.03f}, max {:.03f}, mean'.format(title, min, max) +\n",
        "          ' {:.03f}, 3-sigma ({:.03f}, {:.03f})'.format(mean, mean - 3*std, mean + 3*std) +\n",
        "          ', max-min {:.03f}, 3-sigma range {:.03f}'.format(max - min, 6*std))\n",
        "\n",
        "show_weight_dist(input_activations, 'input')\n",
        "show_weight_dist(conv1_output_activations, 'conv1')\n",
        "show_weight_dist(conv2_output_activations, 'conv2')\n",
        "show_weight_dist(fc1_output_activations, 'fc1')\n",
        "\n",
        "# Plot histograms of the following variables, and calculate their ranges and 3-sigma ranges:\n",
        "#   input_activations\n",
        "#   conv1_output_activations\n",
        "#   conv2_output_activations\n",
        "#   fc1_output_activations\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input min -4.885, max 6.131, mean 0.000, 3-sigma (-3.001, 3.001), max-min 11.016, 3-sigma range 6.002\n",
            "conv1 min 0.000, max 9.238, mean 0.819, 3-sigma (-2.272, 3.911), max-min 9.238, 3-sigma range 6.183\n",
            "conv2 min 0.000, max 3.595, mean 0.164, 3-sigma (-0.982, 1.310), max-min 3.595, 3-sigma range 2.292\n",
            "fc1 min -5.922, max 5.655, mean 0.032, 3-sigma (-9.108, 9.172), max-min 11.576, 3-sigma range 18.280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATZElEQVR4nO3df7DldV3H8ecrCEwsF+QO2f5ot9xqVsukO4jDTDGuwaLk8ocpZLoatTVtpmXZojU4KjNYTYhjWjvs6mIkMqSxJYor4pQzgSz+QAGR2wrubiCbu6DJJC29++N8Fg+3e9m955x7z7n3Ph8zd+73+/l+vue8vzO753U/n++Pk6pCkrS4/cCwC5AkDZ9hIEkyDCRJhoEkCcNAkoRhIEnCMJCmleSOJGcOuw5pLsT7DKThSfIBYG9V/emwa9Hi5shAkmQYSNNJcm+SFyV5a5JrklyZ5Dtt+mh8Ur+LktyZ5GCS9yd5Stv2miSfnfS6leRZSTYCrwTelOS/kvzT3B6h9H2GgXR0XgpcDSwBdgDvmbT9lcDZwE8CPwUccdqnqrYAVwF/XlVPq6pfGWjF0gwYBtLR+WxVXV9VjwEfBJ47aft7qmpPVR0ALgEumPMKpT4YBtLReaBr+RHgKUmO7Wrb07V8H/Bjc1KVNCCGgTQYy7uWVwD/0Za/Czz18IYkPzppPy/n00gwDKTB2JRkWZKTgLcAH27tXwKeneTn20nlt07a75vAT8xdmdLUDANpMP4e+CSwG/h34B0AVfU14G3Ap4B7gM9O2m8rsCbJQ0n+ce7KlZ7Im86kPiW5F/jNqvrUsGuReuXIQJJkGEiSnCaSJOHIQJIEHHvkLqPp5JNPrpUrVw67DElT2L3/uwD8xNgJQ65Ek912223/WVVjk9vnbRisXLmSXbt2DbsMSVN4xd/+GwAf/u0XDLkSTZbkvqnanSaSJBkGkiTDQJKEYSBJwjCQJHEUYZBkW5IHk3ylq+0vknw1ye1JPppkSde2i5JMJLk7ydld7eta20SSzV3tq5Lc0to/nOS4QR6gJOnIjmZk8AFg3aS2ncBzqurngK8BFwEkWQOcDzy77fPeJMckOQb4a+AcYA1wQesL8E7gsqp6FnAQuLCvI5IkzdgRw6Cq/gU4MKntk1V1qK3eDCxry+uBq6vqe1X1dWACOK39TFTV7qp6lM53ya5PEuCFwLVt/+3AeX0ekyRphgZxzuA3gI+35aU88ev/9ra26dqfATzUFSyH26eUZGOSXUl27d+/fwClS5KgzzuQk7wFOARcNZhynlxVbQG2AIyPj/uEPfVt5eaPPb5876Uv6bmPNN/1HAZJXgOcC6yt7z/6dB9P/C7YZa2Nadq/BSxJcmwbHXT3l+aUH/pazHqaJkqyDngT8NKqeqRr0w7g/CTHJ1kFrAY+B9wKrG5XDh1H5yTzjhYiNwEva/tvAK7r7VAkSb06mktLPwT8G/DTSfYmuRB4D/DDwM4kX0zyNwBVdQdwDXAn8AlgU1U91v7q/z3gBuAu4JrWF+BPgD9MMkHnHMLWgR6hJOmIjjhNVFUXTNE87Qd2VV0CXDJF+/XA9VO076ZztZE0MrqnjKTFwDuQJUmGgSTJMJAkYRhIkpjHX3sp9cqTw9L/58hAkmQYSJIMA0kSnjPQIjGo8wQ+v0gLlSMDSZJhIEkyDCRJGAaSJDyBrAXMm8uko+fIQJJkGEiSDANJEoaBJAnDQJKEVxNJPfPRFFpIHBlIkgwDSZLTRNJAOGWk+c6RgSTJMJAkGQaSJI4iDJJsS/Jgkq90tZ2UZGeSe9rvE1t7krw7yUSS25Oc2rXPhtb/niQbutp/IcmX2z7vTpJBH6Qk6ckdzcjgA8C6SW2bgRurajVwY1sHOAdY3X42Au+DTngAFwPPB04DLj4cIK3Pb3XtN/m9JEmz7IhhUFX/AhyY1Lwe2N6WtwPndbVfWR03A0uSPBM4G9hZVQeq6iCwE1jXtv1IVd1cVQVc2fVakqQ50uulpadU1f1t+QHglLa8FNjT1W9va3uy9r1TtE8pyUY6Iw5WrFjRY+layPwOA6k3fZ9Abn/R1wBqOZr32lJV41U1PjY2NhdvKUmLQq9h8M02xUP7/WBr3wcs7+q3rLU9WfuyKdolSXOo1zDYARy+ImgDcF1X+6vbVUWnAw+36aQbgLOSnNhOHJ8F3NC2fTvJ6e0qold3vZYkaY4c8ZxBkg8BZwInJ9lL56qgS4FrklwI3Ae8vHW/HngxMAE8ArwWoKoOJHk7cGvr97aqOnxS+nfpXLH0Q8DH248kaQ4dMQyq6oJpNq2dom8Bm6Z5nW3AtinadwHPOVId0nRG7aSxzynSfOQdyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJNH79xlIQzVqj6CQ5jtHBpIkw0CSZBhIkvCcgTSrfJy15gtHBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEN51pnvDBdNLscmQgSeovDJL8QZI7knwlyYeSPCXJqiS3JJlI8uEkx7W+x7f1ibZ9ZdfrXNTa705ydn+HJEmaqZ7DIMlS4PeB8ap6DnAMcD7wTuCyqnoWcBC4sO1yIXCwtV/W+pFkTdvv2cA64L1Jjum1LmlUrdz8scd/pFHT7zTRscAPJTkWeCpwP/BC4Nq2fTtwXlte39Zp29cmSWu/uqq+V1VfByaA0/qsS5I0Az2HQVXtA/4S+AadEHgYuA14qKoOtW57gaVteSmwp+17qPV/Rnf7FPs8QZKNSXYl2bV///5eS5ckTdLPNNGJdP6qXwX8GHACnWmeWVNVW6pqvKrGx8bGZvOtJGlR6Wea6EXA16tqf1X9D/AR4AxgSZs2AlgG7GvL+4DlAG3704FvdbdPsY8kaQ70EwbfAE5P8tQ2978WuBO4CXhZ67MBuK4t72jrtO2frqpq7ee3q41WAauBz/VRlyRphnq+6ayqbklyLfB54BDwBWAL8DHg6iTvaG1b2y5bgQ8mmQAO0LmCiKq6I8k1dILkELCpqh7rtS5J0sz1dQdyVV0MXDypeTdTXA1UVf8N/Oo0r3MJcEk/tUiSeucdyJIkn02k0eXNWdLccWQgSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiS8A1kaiu67q++99CVDrETqcGQgSXJkoNHi84ik4XBkIEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEl405k0dD6aQqPAkYEkyTCQJBkGkiT6DIMkS5Jcm+SrSe5K8oIkJyXZmeSe9vvE1jdJ3p1kIsntSU7tep0Nrf89STb0e1CSpJnpd2RwOfCJqvoZ4LnAXcBm4MaqWg3c2NYBzgFWt5+NwPsAkpwEXAw8HzgNuPhwgEiS5kbPYZDk6cAvAlsBqurRqnoIWA9sb922A+e15fXAldVxM7AkyTOBs4GdVXWgqg4CO4F1vdYlSZq5fkYGq4D9wPuTfCHJFUlOAE6pqvtbnweAU9ryUmBP1/57W9t07f9Pko1JdiXZtX///j5KlyR16ycMjgVOBd5XVc8Dvsv3p4QAqKoCqo/3eIKq2lJV41U1PjY2NqiXlaRFr5+bzvYCe6vqlrZ+LZ0w+GaSZ1bV/W0a6MG2fR+wvGv/Za1tH3DmpPbP9FGX5hm/3Uwavp5HBlX1ALAnyU+3prXAncAO4PAVQRuA69ryDuDV7aqi04GH23TSDcBZSU5sJ47Pam2SpDnS7+MoXgdcleQ4YDfwWjoBc02SC4H7gJe3vtcDLwYmgEdaX6rqQJK3A7e2fm+rqgN91iVJmoG+wqCqvgiMT7Fp7RR9C9g0zetsA7b1U4skqXc+qE4aIT60TsPi4ygkSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCx1FoSHxstTRaHBlIkgwDSZLTRNLI8gmmmkuODCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSWIAj6NIcgywC9hXVecmWQVcDTwDuA14VVU9muR44ErgF4BvAa+oqnvba1wEXAg8Bvx+Vd3Qb10aPT6pVBpdgxgZvB64q2v9ncBlVfUs4CCdD3na74Ot/bLWjyRrgPOBZwPrgPe2gJEkzZG+wiDJMuAlwBVtPcALgWtbl+3AeW15fVunbV/b+q8Hrq6q71XV14EJ4LR+6pIkzUy/I4N3AW8C/retPwN4qKoOtfW9wNK2vBTYA9C2P9z6P94+xT6SpDnQ8zmDJOcCD1bVbUnOHFxJT/qeG4GNACtWrJiLt5RGgo+z1mzrZ2RwBvDSJPfSOWH8QuByYEmSwyGzDNjXlvcBywHa9qfTOZH8ePsU+zxBVW2pqvGqGh8bG+ujdElSt57DoKouqqplVbWSzgngT1fVK4GbgJe1bhuA69ryjrZO2/7pqqrWfn6S49uVSKuBz/ValyRp5mbjm87+BLg6yTuALwBbW/tW4INJJoADdAKEqrojyTXAncAhYFNVPTYLdUmSpjGQMKiqzwCfacu7meJqoKr6b+BXp9n/EuCSQdQiSZo570CWJBkGkqTZOWcgPc5HUEjzgyMDSZJhIEkyDCRJeM5Amnd8NIVmgyMDSZJhIEkyDCRJGAaSJAwDSRJeTaRZ4F3H0vzjyECSZBhIkgwDSRKeM5DmtcnnZ7wjWb1yZCBJMgwkSYaBJAnDQJKEYSBJwquJNCDedSzNb44MJEmGgSTJaSJpQfErMdWrnkcGSZYnuSnJnUnuSPL61n5Skp1J7mm/T2ztSfLuJBNJbk9yatdrbWj970myof/DkiTNRD/TRIeAN1bVGuB0YFOSNcBm4MaqWg3c2NYBzgFWt5+NwPugEx7AxcDzgdOAiw8HiCRpbvQcBlV1f1V9vi1/B7gLWAqsB7a3btuB89ryeuDK6rgZWJLkmcDZwM6qOlBVB4GdwLpe65IkzdxAzhkkWQk8D7gFOKWq7m+bHgBOactLgT1du+1tbdO1T/U+G+mMKlixYsUgSlcfvJxUWjj6vpooydOAfwDeUFXf7t5WVQVUv+/R9Xpbqmq8qsbHxsYG9bKStOj1FQZJfpBOEFxVVR9pzd9s0z+03w+29n3A8q7dl7W26dolSXOkn6uJAmwF7qqqv+ratAM4fEXQBuC6rvZXt6uKTgcebtNJNwBnJTmxnTg+q7VJ6sPKzR97/Ec6kn7OGZwBvAr4cpIvtrY3A5cC1yS5ELgPeHnbdj3wYmACeAR4LUBVHUjyduDW1u9tVXWgj7okSTPUcxhU1WeBTLN57RT9C9g0zWttA7b1WoskqT/egawZccphfvLOZB2JzyaSJBkGkiTDQJKE5wx0FDxPIC18jgwkSYaBJMkwkCRhGEiS8ASytOh4A5qm4shAkuTIQFPzctLFwVGCDnNkIEkyDCRJThOpi1ND0uLlyECS5MhAUocnkxc3w2CRc2pIEjhNJEnCkYGkKThltPgYBouQU0OSJjMMFgkDQL1ylLA4GAaSjprBsHAZBguYowFJR8swkNQTRwkLi2GwwDga0DAYDPPfyIRBknXA5cAxwBVVdemQSxppfuhrVPlvc34aiTBIcgzw18AvA3uBW5PsqKo7h1vZaPE/meab6f7NOnoYPSMRBsBpwERV7QZIcjWwHliwYeAHuxazfv79GySzY1TCYCmwp2t9L/D8yZ2SbAQ2ttX/SnL3HNTWi5OB/xx2EbNoIR+fxzbi8s4pmxfEsT2JQR7fj0/VOCphcFSqaguwZdh1HEmSXVU1Puw6ZstCPj6PbX5ayMcGc3N8o/Kgun3A8q71Za1NkjQHRiUMbgVWJ1mV5DjgfGDHkGuSpEVjJKaJqupQkt8DbqBzaem2qrpjyGX1Y+Snsvq0kI/PY5ufFvKxwRwcX6pqtt9DkjTiRmWaSJI0RIaBJMkwmG1J3pikkpw87FoGJclfJPlqktuTfDTJkmHX1K8k65LcnWQiyeZh1zNISZYnuSnJnUnuSPL6Ydc0aEmOSfKFJP887FoGKcmSJNe2/293JXnBbL2XYTCLkiwHzgK+MexaBmwn8Jyq+jnga8BFQ66nL12PQzkHWANckGTNcKsaqEPAG6tqDXA6sGmBHR/A64G7hl3ELLgc+ERV/QzwXGbxGA2D2XUZ8CZgQZ2lr6pPVtWhtnoznftC5rPHH4dSVY8Chx+HsiBU1f1V9fm2/B06HyhLh1vV4CRZBrwEuGLYtQxSkqcDvwhsBaiqR6vqodl6P8NgliRZD+yrqi8Nu5ZZ9hvAx4ddRJ+mehzKgvmw7JZkJfA84JbhVjJQ76LzR9f/DruQAVsF7Afe36bArkhywmy92UjcZzBfJfkU8KNTbHoL8GY6U0Tz0pMdW1Vd1/q8hc4UxFVzWZt6k+RpwD8Ab6iqbw+7nkFIci7wYFXdluTMYdczYMcCpwKvq6pbklwObAb+bLbeTD2qqhdN1Z7kZ+mk+peSQGca5fNJTquqB+awxJ5Nd2yHJXkNcC6wtub/zSoL/nEoSX6QThBcVVUfGXY9A3QG8NIkLwaeAvxIkr+rql8fcl2DsBfYW1WHR3HX0gmDWeFNZ3Mgyb3AeFUtiKcqti8i+ivgl6pq/7Dr6VeSY+mcCF9LJwRuBX5tnt8F/7h0/iLZDhyoqjcMu57Z0kYGf1RV5w67lkFJ8q/Ab1bV3UneCpxQVX88G+/lyEC9eA9wPLCzjXxurqrfGW5JvVuAj0OZ7AzgVcCXk3yxtb25qq4fYk06Oq8DrmrPbNsNvHa23siRgSTJq4kkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJwP8BcbCmo1umZd8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9PUHh4NjKc5"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haiPVx4ibEra"
      },
      "source": [
        "# Part 4: Quantize Activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLjSp7hsXofq"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "class NetQuantized(nn.Module):\n",
        "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
        "        super(NetQuantized, self).__init__()\n",
        "        \n",
        "        net_init = copy_model(net_with_weights_quantized)\n",
        "\n",
        "        self.conv1 = net_init.conv1\n",
        "        self.pool = net_init.pool\n",
        "        self.conv2 = net_init.conv2\n",
        "        self.fc1 = net_init.fc1\n",
        "\n",
        "        for layer in self.conv1, self.conv2, self.fc1:\n",
        "            def pre_hook(l, x):\n",
        "                x = x[0]\n",
        "                if (x < -128).any() or (x > 127).any():\n",
        "                    raise Exception(\"Input to {} layer is out of bounds for an 8-bit signed integer\".format(l.__class__.__name__))\n",
        "                if (x != x.round()).any():\n",
        "                    raise Exception(\"Input to {} layer has non-integer values\".format(l.__class__.__name__))\n",
        "\n",
        "            layer.register_forward_pre_hook(pre_hook)\n",
        "\n",
        "        # Calculate the scaling factor for the initial input to the CNN\n",
        "        self.input_activations = net_with_weights_quantized.input_activations\n",
        "        self.input_scale = NetQuantized.quantize_initial_input(self.input_activations)\n",
        "\n",
        "        # Calculate the output scaling factors for all the layers of the CNN\n",
        "        preceding_layer_scales = []\n",
        "        for layer in self.conv1, self.conv2, self.fc1:\n",
        "            layer.output_scale = NetQuantized.quantize_activations(layer.activations, layer.weight.scale, self.input_scale, preceding_layer_scales)\n",
        "            preceding_layer_scales.append((layer.weight.scale, layer.output_scale))\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_initial_input(pixels: np.ndarray) -> float:\n",
        "        '''\n",
        "        Calculate a scaling factor for the images that are input to the first layer of the CNN.\n",
        "\n",
        "        Parameters:\n",
        "        pixels (ndarray): The values of all the pixels which were part of the input image during training\n",
        "\n",
        "        Returns:\n",
        "        float: A scaling factor that the input should be multiplied by before being fed into the first layer.\n",
        "               This value does not need to be an 8-bit integer.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        absmax = np.abs(pixels).max()\n",
        "        return 127 / absmax\n",
        "\n",
        "    @staticmethod\n",
        "    def quantize_activations(activations: np.ndarray, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> float:\n",
        "        '''\n",
        "        Calculate a scaling factor to multiply the output of a layer by.\n",
        "\n",
        "        Parameters:\n",
        "        activations (ndarray): The values of all the pixels which have been output by this layer during training\n",
        "        n_w (float): The scale by which the weights of this layer were multiplied as part of the \"quantize_weights\" function you wrote earlier\n",
        "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
        "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
        "\n",
        "        Returns:\n",
        "        float: A scaling factor that the layer output should be multiplied by before being fed into the first layer.\n",
        "               This value does not need to be an 8-bit integer.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        max = activations.max()\n",
        "        product = 1\n",
        "        for prev_scaling in ns:\n",
        "            product *= prev_scaling[0] * prev_scaling[1]\n",
        "        scale = 127 / (n_w * product * n_initial_input * max)  # return this for original output\n",
        "        return 2 ** np.floor(np.log2(scale))  # make scaling a power of 2!\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # You can access the output activation scales like this:\n",
        "        #   fc1_output_scale = self.fc1.output_scale\n",
        "\n",
        "        # To make sure that the outputs of each layer are integers between -128 and 127, you may need to use the following functions:\n",
        "        #   * torch.Tensor.round\n",
        "        #   * torch.clamp\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        x = x.reshape((x.shape[0], 50, 13)).transpose(1, 2)\n",
        "        x = torch.clamp(torch.round(x * self.input_scale), min=-128, max=127)\n",
        "        x = self.pool(torch.clamp(torch.floor(F.relu(self.conv1(x)) * self.conv1.output_scale), min=-128, max=127))\n",
        "        x = self.pool(torch.clamp(torch.floor(F.relu(self.conv2(x)) * self.conv2.output_scale), min=-128, max=127))\n",
        "        x = x.reshape((x.shape[0], 16*13))\n",
        "        #x = torch.clamp(torch.floor(self.fc1(x) * self.fc1.output_scale), min=-128, max=127)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CpHgvE994J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ee8257-01cc-4dfe-c86a-6b69de3af53d"
      },
      "source": [
        "# Merge the information from net_q2 and net_q3 together\n",
        "net_init = copy_model(net_q2)\n",
        "net_init.input_activations = deepcopy(net_q3.input_activations)\n",
        "for layer_init, layer_q3 in zip(net_init.children(), net_q3.children()):\n",
        "    if isinstance(layer_init, nn.Conv1d) or isinstance(layer_init, nn.Linear):\n",
        "        layer_init.activations = deepcopy(layer_q3.activations)\n",
        "\n",
        "net_quantized = NetQuantized(net_init)\n",
        "\n",
        "for l in [net_quantized.conv1, net_quantized.conv2, net_quantized.fc1]:\n",
        "    print(np.log2(l.output_scale))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-8.)\n",
            "tensor(-6.)\n",
            "tensor(-9.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur6Rckyjy7tS",
        "outputId": "7dd26768-0f56-41e0-db8e-518f86ee8f84"
      },
      "source": [
        "score = test(net_quantized, trainloader)\n",
        "print('Accuracy of the network after quantizing activations (train): {}%'.format(score))\n",
        "score = test(net_quantized, testloader)\n",
        "print('Accuracy of the network after quantizing activations (test): {}%'.format(score))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network after quantizing activations (train): 98.85133642588912%\n",
            "Accuracy of the network after quantizing activations (test): 97.74685222001325%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpnyPRxzyNc8"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jTOL7scbMs7"
      },
      "source": [
        "# Part 5: Quantize Biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JI3f00ZdVKM"
      },
      "source": [
        "class NetWithBias(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetWithBias, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(13, 8, 3, padding=1, bias=True)\n",
        "        self.pool = nn.MaxPool1d(2, 2, ceil_mode=True)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.conv2 = nn.Conv1d(8, 16, 3, padding=1, bias=True)\n",
        "        self.fc1 = nn.Linear(16 * 13, 2, bias=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.reshape((x.shape[0], 50, 13)).transpose(1, 2)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = x.reshape((x.shape[0], 16*13))\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "net_with_bias = NetWithBias().to(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjk3hEQaVDpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b0b4ac-2978-4423-91f2-fa597af9dfac"
      },
      "source": [
        "train(net_with_bias, trainloader)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10] loss: 62.138\n",
            "[20] loss: 38.561\n",
            "[30] loss: 28.431\n",
            "[40] loss: 23.876\n",
            "[50] loss: 20.896\n",
            "[60] loss: 20.488\n",
            "[70] loss: 18.399\n",
            "[80] loss: 18.213\n",
            "[90] loss: 17.099\n",
            "[100] loss: 16.536\n",
            "[110] loss: 15.703\n",
            "[120] loss: 16.340\n",
            "[130] loss: 15.088\n",
            "[140] loss: 14.985\n",
            "[150] loss: 14.614\n",
            "[160] loss: 14.366\n",
            "[170] loss: 14.264\n",
            "[180] loss: 13.663\n",
            "[190] loss: 13.873\n",
            "[200] loss: 13.866\n",
            "[210] loss: 13.141\n",
            "[220] loss: 12.758\n",
            "[230] loss: 13.170\n",
            "[240] loss: 11.777\n",
            "[250] loss: 11.640\n",
            "[260] loss: 12.395\n",
            "[270] loss: 12.166\n",
            "[280] loss: 11.114\n",
            "[290] loss: 12.458\n",
            "[300] loss: 11.189\n",
            "[310] loss: 11.802\n",
            "[320] loss: 12.069\n",
            "[330] loss: 10.944\n",
            "[340] loss: 12.660\n",
            "[350] loss: 11.461\n",
            "[360] loss: 11.260\n",
            "[370] loss: 10.928\n",
            "[380] loss: 11.372\n",
            "[390] loss: 10.166\n",
            "[400] loss: 11.722\n",
            "[410] loss: 9.755\n",
            "[420] loss: 11.386\n",
            "[430] loss: 10.649\n",
            "[440] loss: 10.041\n",
            "[450] loss: 11.278\n",
            "[460] loss: 10.449\n",
            "[470] loss: 10.801\n",
            "[480] loss: 10.840\n",
            "[490] loss: 9.968\n",
            "[500] loss: 9.418\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9ohsZVmdpGm",
        "outputId": "57569991-df3a-46b9-e3a3-8d934dc25e21"
      },
      "source": [
        "score = test(net_with_bias, trainloader)\n",
        "print('Accuracy of the network with bias (train): {}%'.format(score))\n",
        "score = test(net_with_bias, testloader)\n",
        "print('Accuracy of the network with bias (test): {}%'.format(score))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network with bias (train): 99.13850231941683%\n",
            "Accuracy of the network with bias (test): 98.07819748177602%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ZiJk6yEEM-"
      },
      "source": [
        "register_activation_profiling_hooks(net_with_bias)\n",
        "test(net_with_bias, trainloader, max_samples=400)\n",
        "net_with_bias.profile_activations = False"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZwk8KLtAUAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883a352a-f4f3-4cf8-956d-0d4c0b5399c2"
      },
      "source": [
        "net_with_bias_with_quantized_weights = copy_model(net_with_bias)\n",
        "quantize_layer_weights(net_with_bias_with_quantized_weights)\n",
        "\n",
        "score = test(net_with_bias_with_quantized_weights, trainloader)\n",
        "print('Accuracy of the network on the train images after all the weights are quantized but the bias isn\\'t: {}%'.format(score))\n",
        "score = test(net_with_bias_with_quantized_weights, testloader)\n",
        "print('Accuracy of the network on the test images after all the weights are quantized but the bias isn\\'t: {}%'.format(score))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the train images after all the weights are quantized but the bias isn't: 58.47139385906782%\n",
            "Accuracy of the network on the test images after all the weights are quantized but the bias isn't: 58.316766070245194%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO2Gdu_tEZ4v"
      },
      "source": [
        "class NetQuantizedWithBias(NetQuantized):\n",
        "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
        "        super(NetQuantizedWithBias, self).__init__(net_with_weights_quantized)\n",
        "\n",
        "\n",
        "        for i, l in enumerate([self.conv1, self.conv2, self.fc1]):\n",
        "            preceding_scales = [(layer.weight.scale, layer.output_scale) for layer in self.children() if isinstance(layer, nn.Conv1d) or isinstance(layer, nn.Linear)][:i]\n",
        "\n",
        "            l.bias.data = NetQuantizedWithBias.quantized_bias(\n",
        "                l.bias.data,\n",
        "                l.weight.scale,\n",
        "                self.input_scale,\n",
        "                preceding_scales\n",
        "            )\n",
        "\n",
        "            if (l.bias.data < -2147483648).any() or (l.bias.data > 2147483647).any():\n",
        "                raise Exception(\"Bias has values which are out of bounds for an 32-bit signed integer\")\n",
        "            if (l.bias.data != l.bias.data.round()).any():\n",
        "                raise Exception(\"Bias has non-integer values\")\n",
        "\n",
        "    @staticmethod\n",
        "    def quantized_bias(bias: torch.Tensor, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> torch.Tensor:\n",
        "        '''\n",
        "        Quantize the bias so that all values are integers between -2147483648 and 2147483647.\n",
        "\n",
        "        Parameters:\n",
        "        bias (Tensor): The floating point values of the bias\n",
        "        n_w (float): The scale by which the weights of this layer were multiplied\n",
        "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
        "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The bias in quantized form, where every value is an integer between -2147483648 and 2147483647.\n",
        "                The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
        "        '''\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        product = 1\n",
        "        for prev_scaling in ns:\n",
        "            product *= prev_scaling[0] * prev_scaling[1]\n",
        "        scale = (n_w * product * n_initial_input)\n",
        "        return (bias * scale).round()\n",
        "        #return torch.clamp((bias * 2.5).round(), min=-2147483648, max=2147483647)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA6rXt3Q-zF8"
      },
      "source": [
        "net_quantized_with_bias = NetQuantizedWithBias(net_with_bias_with_quantized_weights)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9ho_iCwfVoG",
        "outputId": "57ed8bcd-b15a-4eb8-b139-1a40ff94e747"
      },
      "source": [
        "score = test(net_quantized_with_bias, trainloader)\n",
        "print('Accuracy of the network with quantized weights and bias (train): {}%'.format(score))\n",
        "score = test(net_quantized_with_bias, testloader)\n",
        "print('Accuracy of the network with quantized weights and bias (test): {}%'.format(score))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network with quantized weights and bias (train): 99.20477137176938%\n",
            "Accuracy of the network with quantized weights and bias (test): 98.01192842942346%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ga8xxxLhrc_",
        "outputId": "123ecb71-12cb-4ad4-b454-5ed43e8b7747"
      },
      "source": [
        "print('Number of parameters in each layer:')\n",
        "for p in net_quantized_with_bias.parameters():\n",
        "    print(p.numel())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters in each layer:\n",
            "312\n",
            "8\n",
            "384\n",
            "16\n",
            "416\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDriUNRThyQF"
      },
      "source": [
        "# Part 6: Numpy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgbtLHSRh3Pd"
      },
      "source": [
        "conv1_weights = net_quantized_with_bias.conv1.weight.data.cpu().numpy().astype(np.int8)\n",
        "conv1_biases = net_quantized_with_bias.conv1.bias.data.cpu().numpy().astype(np.int32)\n",
        "conv2_weights = net_quantized_with_bias.conv2.weight.data.cpu().numpy().astype(np.int8)\n",
        "conv2_biases = net_quantized_with_bias.conv2.bias.data.cpu().numpy().astype(np.int32)\n",
        "fc1_weights = net_quantized_with_bias.fc1.weight.data.cpu().numpy().astype(np.int8)\n",
        "fc1_biases = net_quantized_with_bias.fc1.bias.data.cpu().numpy().astype(np.int32)\n",
        "\n",
        "# transpose the weights so that they match the numpy model\n",
        "conv1_weights = np.transpose(conv1_weights, (2, 1, 0))\n",
        "conv2_weights = np.transpose(conv2_weights, (2, 1, 0))\n",
        "#fc1_weights = np.transpose(fc1_weights, (1, 0))  # works if x is transposed\n",
        "fc1_weights = np.transpose(fc1_weights.reshape(2, 16, 13), (0, 2, 1)).reshape(2, 208).T\n",
        "\n",
        "# get the featuremap scalings\n",
        "input_scale = net_quantized_with_bias.input_scale\n",
        "conv1_output_scale = net_quantized_with_bias.conv1.output_scale\n",
        "conv2_output_scale = net_quantized_with_bias.conv2.output_scale\n",
        "fc1_output_scale = net_quantized_with_bias.fc1.output_scale\n",
        "\n",
        "# bitshifts is the amount that each featuremap is shifted to the right eg: 8 would be a divide by 256\n",
        "bitshifts = -np.log2(np.array([conv1_output_scale, conv2_output_scale, fc1_output_scale])).astype(np.int8)\n",
        "\n",
        "input_scale_arr = np.array(input_scale)  # single element array for input featuremap scaling\n",
        "\n",
        "weights_list = [input_scale_arr, bitshifts,\n",
        "                conv1_weights, conv1_biases,\n",
        "                conv2_weights, conv2_biases,\n",
        "                fc1_weights, fc1_biases]\n",
        "np.savez('parameters_quantized.npz', *weights_list)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIeMZLeW7Fer",
        "outputId": "531fe485-856c-4bc6-e011-a708a7eaea97"
      },
      "source": [
        "weights_archive = np.load('parameters_quantized.npz')\n",
        "weights_list = [weights_archive['arr_{}'.format(i)] for i in range(len(weights_archive))]\n",
        "\n",
        "for weights in weights_list:\n",
        "    print(weights.shape)\n",
        "\n",
        "input_scale = weights_list[0]\n",
        "bitshifts = weights_list[1]\n",
        "conv1_weights = weights_list[2]\n",
        "conv1_biases = weights_list[3]\n",
        "conv2_weights = weights_list[4]\n",
        "conv2_biases = weights_list[5]\n",
        "fc1_weights = weights_list[6]\n",
        "fc1_biases = weights_list[7]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "()\n",
            "(3,)\n",
            "(3, 13, 8)\n",
            "(8,)\n",
            "(3, 8, 16)\n",
            "(16,)\n",
            "(208, 2)\n",
            "(2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyl-WV3OiRpP"
      },
      "source": [
        "def relu(x):\n",
        "    return np.maximum(x, 0)\n",
        "\n",
        "def conv1d_single_kernel(x, weights, bias):\n",
        "    '''Perform convolution of a input feature map with a single filter and bias.\n",
        "    \n",
        "    featuremap dims are (time, n_coeffs), so (50, 13)\n",
        "    '''\n",
        "    out = np.zeros(x.shape[0], dtype=np.int64)  # output length is the same\n",
        "    x_pad = np.zeros((x.shape[0]+2, x.shape[1]), dtype=np.int64)\n",
        "    x_pad[1:-1,:] = x  # zero padding\n",
        "    for i in range(x.shape[0]):\n",
        "        section = x_pad[i:i+3,:]\n",
        "        out[i] = relu(np.sum(section * weights) + bias)\n",
        "    return out\n",
        "\n",
        "def conv1d_multi_kernel(x, weights, biases):\n",
        "    n_kernels = weights.shape[2]\n",
        "    out = np.zeros((x.shape[0], n_kernels), dtype=np.int64)\n",
        "    for i in range(n_kernels):\n",
        "        kernel = weights[:,:,i]\n",
        "        out[:,i] = conv1d_single_kernel(x, kernel, biases[i])\n",
        "    return out\n",
        "\n",
        "def max_pool_1d(x):\n",
        "    out = np.zeros((int(np.ceil(x.shape[0] / 2)), x.shape[1]), dtype=np.int8)\n",
        "    for j in range(x.shape[1]):\n",
        "        for i in range(int(np.floor(x.shape[0] / 2))):\n",
        "            out[i, j] = np.maximum(x[2*i, j], x[2*i+1, j])\n",
        "        if (x.shape[0] % 2 == 1):\n",
        "            out[-1, j] = x[-1, j]\n",
        "    return out\n",
        "\n",
        "def fc(x, weights, biases):\n",
        "    x = x.flatten()\n",
        "    out = np.matmul(x, weights, dtype=np.int64) + biases\n",
        "    return out\n",
        "\n",
        "def scale_feature_map(x, shift):\n",
        "    '''Scale a featuremap to a byte range given the amount to right shift by.\n",
        "\n",
        "    Since all weight, bias, and activation quantizations are mapped using the full range\n",
        "    of values, there is not any need for clamping the values to the range [-128, 127].\n",
        "    However, it is still useful since the quantization could be changed to not map to the\n",
        "    full range of the unquantized values.\n",
        "    '''\n",
        "    x = np.right_shift(x, shift)\n",
        "    x = np.clip(x, -128, 127)\n",
        "    x = x.astype(np.int8)\n",
        "    return x\n",
        "\n",
        "def get_numpy_pred(features):\n",
        "    out = np.zeros((features.shape[0], 2), dtype=np.int64)\n",
        "    for i in range(features.shape[0]):\n",
        "        # condition input feature map\n",
        "        x = features[i]\n",
        "        x = x.reshape((int(x.size / 13), 13))\n",
        "        x = np.clip(np.round(x * input_scale), -128, 127).astype(np.int8)\n",
        "\n",
        "        # conv1\n",
        "        x = conv1d_multi_kernel(x, conv1_weights, conv1_biases)\n",
        "        x = scale_feature_map(x, bitshifts[0])\n",
        "        x = max_pool_1d(x)\n",
        "\n",
        "        # conv2\n",
        "        x = conv1d_multi_kernel(x, conv2_weights, conv2_biases)\n",
        "        x = scale_feature_map(x, bitshifts[1])\n",
        "        x = max_pool_1d(x)\n",
        "\n",
        "        # fc1\n",
        "        x = fc(x, fc1_weights, fc1_biases)\n",
        "        \n",
        "        out[i] = x\n",
        "    return out"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxDv67ZHvR3n",
        "outputId": "2cf969a5-0d62-4cff-f52c-e9dd8634ac2b"
      },
      "source": [
        "numpy_pred = get_numpy_pred(X[:1,:])\n",
        "numpy_pred.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkgYmJvV7_Fa",
        "outputId": "2a87c450-1b6c-4f20-f822-0f63e19f6576"
      },
      "source": [
        "def get_torch_pred(input):\n",
        "    return net_quantized_with_bias.forward(torch.tensor(input, device=device, dtype=torch.float)).detach().cpu().numpy()\n",
        "\n",
        "torch_pred = get_torch_pred(X[:1,:])\n",
        "torch_pred.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQPCZMWDRTGi",
        "outputId": "62203893-c83f-4e5d-e730-c7fc341ab117"
      },
      "source": [
        "numpy_pred - torch_pred"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr6r5V359-4s",
        "outputId": "91e85f13-82b2-4ce2-acc3-01fed11a0a61"
      },
      "source": [
        "# compare output for each sample in test data\n",
        "\n",
        "n_err = 0\n",
        "for i in range(Xtest.shape[0]):\n",
        "    numpy_pred = get_numpy_pred(X[i:i+1, :])\n",
        "    torch_pred = get_torch_pred(X[i:i+1, :])\n",
        "    diff = numpy_pred - torch_pred\n",
        "    if np.abs(diff).max() > 1e-9:\n",
        "        n_err += 1\n",
        "        print('Difference between outputs at sample ', i)\n",
        "    if n_err > 10:\n",
        "        break\n",
        "\n",
        "if n_err == 0:\n",
        "    print('No differences between numpy model and torch model!')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No differences between numpy model and torch model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Tsq1QbEyqA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yXTLUELLMex"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}