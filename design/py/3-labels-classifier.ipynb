{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from Edge Impulse. You can obtain the URL from the Dashboard, right-click on the download icon next to 'Spectral features data' and 'Spectral features labels', and click **Copy link location**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "API_KEY = 'ei_9eedce842a674656748bf65a19f0e2a80cc867cde21a7810354f75a4fb565a3d'\n",
    "\n",
    "X = (requests.get('https://studio.edgeimpulse.com/v1/api/24007/training/9/x', headers={'x-api-key': API_KEY})).content\n",
    "Y = (requests.get('https://studio.edgeimpulse.com/v1/api/24007/training/9/y', headers={'x-api-key': API_KEY})).content\n",
    "with open('x_train.npy', 'wb') as file:\n",
    "    file.write(X)\n",
    "with open('y_train.npy', 'wb') as file:\n",
    "    file.write(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the data in a temporary file, and load it back through Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('x_train.npy')\n",
    "Y = np.load('y_train.npy')[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our labels and split the data up in a test and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Set random seeds for repeatable results\n",
    "RANDOM_SEED = 3\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "classes_values = [ \"noise\", \"unknown\", \"yes\" ]\n",
    "classes = len(classes_values)\n",
    "\n",
    "Y = tf.keras.utils.to_categorical(Y - 1, classes)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "input_length = X_train[0].shape[0]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "\n",
    "def set_batch_size(batch_size, train_dataset, validation_dataset):\n",
    "    train_dataset = train_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "callbacks = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(Reshape((int(input_length / 13), 13), input_shape=(input_length, )))\n",
    "model.add(Conv1D(8, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(classes, activation='softmax', name='y_pred'))\n",
    "\n",
    "# this controls the learning rate\n",
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
    "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
    "BATCH_SIZE = 32\n",
    "train_dataset, validation_dataset = set_batch_size(BATCH_SIZE, train_dataset, validation_dataset)\n",
    "\n",
    "# train the neural network\n",
    "retrain = False  # if you don't have the weights already\n",
    "if retrain:\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    model.fit(train_dataset, epochs=100, validation_data=validation_dataset, verbose=2, callbacks=callbacks)\n",
    "    \n",
    "    # Save the model to disk\n",
    "    model.save('saved_model')\n",
    "    weights_list = model.get_weights()\n",
    "    np.savez('weights_float32.npz', *weights_list)\n",
    "else:  # otherwise reload weights from disk\n",
    "    weights_archive = np.load('weights_float32.npz')\n",
    "    weights_list = [weights_archive['arr_{}'.format(i)] for i in range(len(weights_archive))]\n",
    "    model.set_weights(weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 50, 13)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 50, 8)             320       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 25, 8)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 25, 16)            400       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 208)               0         \n",
      "_________________________________________________________________\n",
      "y_pred (Dense)               (None, 3)                 627       \n",
      "=================================================================\n",
      "Total params: 1,347\n",
      "Trainable params: 1,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 13, 8)\n",
      "(8,)\n",
      "(3, 8, 16)\n",
      "(16,)\n",
      "(208, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "#weights_list = model.get_weights()\n",
    "for weights in weights_list:\n",
    "    print(weights.shape)\n",
    "conv1_weights = weights_list[0]\n",
    "conv1_biases = weights_list[1]\n",
    "conv2_weights = weights_list[2]\n",
    "conv2_biases = weights_list[3]\n",
    "dense_weights = weights_list[4]\n",
    "dense_biases = weights_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3613, 650)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def conv1d_single_kernel(x, weights, bias):\n",
    "    '''Perform convolution of a input feature map with a single filter and bias.\n",
    "    \n",
    "    featuremap dims are (time, n_coeffs), so (50, 13)\n",
    "    '''\n",
    "    out = np.zeros(x.shape[0], dtype=np.float32)  # output length is the same\n",
    "    x_pad = np.zeros((x.shape[0]+2, x.shape[1]), dtype=np.float32)\n",
    "    x_pad[1:-1,:] = x  # zero padding\n",
    "    for i in range(x.shape[0]):\n",
    "        section = x_pad[i:i+3,:]\n",
    "        out[i] = relu(np.sum(section * weights) + bias)\n",
    "    return out\n",
    "\n",
    "def conv1d_multi_kernel(x, weights, biases):\n",
    "    n_kernels = weights.shape[2]\n",
    "    out = np.zeros((x.shape[0], n_kernels), dtype=np.float32)\n",
    "    for i in range(n_kernels):\n",
    "        kernel = weights[:,:,i]\n",
    "        out[:,i] = conv1d_single_kernel(x, kernel, biases[i])\n",
    "    return out\n",
    "\n",
    "def max_pool_1d(x):\n",
    "    out = np.zeros((int(np.ceil(x.shape[0] / 2)), x.shape[1]), dtype=np.float32)\n",
    "    for j in range(x.shape[1]):\n",
    "        for i in range(int(np.floor(x.shape[0] / 2))):\n",
    "            out[i, j] = np.maximum(x[2*i, j], x[2*i+1, j])\n",
    "        if (x.shape[0] % 2 == 1):\n",
    "            out[-1, j] = x[-1, j]\n",
    "    return out\n",
    "\n",
    "def dense(x, weights, biases):\n",
    "    x = x.flatten()\n",
    "    out = softmax(np.matmul(x, weights) + biases)\n",
    "    return out\n",
    "\n",
    "def classify(features):\n",
    "#     out = np.zeros((features.shape[0], 3), dtype=np.float32)\n",
    "    out = np.zeros((features.shape[0], 50, 8))\n",
    "    for i in range(features.shape[0]):\n",
    "        x = features[i]\n",
    "        x = x.reshape((int(x.size / 13), 13))\n",
    "        conv1 = conv1d_multi_kernel(x, conv1_weights, conv1_biases)\n",
    "#         max_pool1 = max_pool_1d(conv1)\n",
    "#         conv2 = conv1d_multi_kernel(max_pool1, conv2_weights, conv2_biases)\n",
    "#         max_pool2 = max_pool_1d(conv2)\n",
    "#         dense1 = dense(max_pool2, dense_weights, dense_biases)\n",
    "#         out[i] = dense1\n",
    "        out[i] = conv1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (50,8) into shape (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d72dd82fe138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmy_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-a0beca1e7690>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#         dense1 = dense(max_pool2, dense_weights, dense_biases)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#         out[i] = dense1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (50,8) into shape (3)"
     ]
    }
   ],
   "source": [
    "my_pred = classify(X[:20,:])\n",
    "my_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second copy of model to experiment with\n",
    "model2 = Sequential()\n",
    "model2.add(Reshape((int(input_length / 13), 13), input_shape=(input_length, )))\n",
    "model2.add(Conv1D(8, kernel_size=3, activation='relu', padding='same'))\n",
    "#model2.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "#model2.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
    "#model2.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "#model2.add(Flatten())\n",
    "#model2.add(Dense(classes, activation='softmax', name='y_pred'))\n",
    "model2.set_weights(weights_list[:2])\n",
    "#model2.summary()\n",
    "keras_pred = model2.predict(X[:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,3) (20,50,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4cb4c14d647e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkeras_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdiff\u001b[0m  \u001b[0;31m# difference should all be small values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,3) (20,50,8) "
     ]
    }
   ],
   "source": [
    "diff = my_pred - keras_pred\n",
    "diff  # difference should all be small values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f80218b0b70>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(conv1_weights.shape)\n",
    "# scale = 0.014854089356958866\n",
    "# zero_point = 0\n",
    "# quant = conv1_weights[:,:,0] / scale + zero_point\n",
    "# quant.flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dense_weights.shape)\n",
    "# scale = 0.0089818863198161125\n",
    "# quant = dense_weights / scale\n",
    "# quant.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    n_samples = 100\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(X).batch(1).take(100):\n",
    "        # Model has only one input so each data point has one element.\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'reshape_1_input_int8',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 650], dtype=int32),\n",
       "  'shape_signature': array([ -1, 650], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.036910686641931534, -9),\n",
       "  'quantization_parameters': {'scales': array([0.03691069], dtype=float32),\n",
       "   'zero_points': array([-9], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/conv1d_2/BiasAdd/ReadVariableOp/resource',\n",
       "  'index': 1,\n",
       "  'shape': array([8], dtype=int32),\n",
       "  'shape_signature': array([8], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00051168, 0.0002173 , 0.00025702, 0.00027215, 0.00028592,\n",
       "          0.00025434, 0.00027363, 0.00034526], dtype=float32),\n",
       "   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/conv1d_2/conv1d/ExpandDims/dim',\n",
       "  'index': 2,\n",
       "  'shape': array([], dtype=int32),\n",
       "  'shape_signature': array([], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/reshape_1/Reshape/shape/1',\n",
       "  'index': 3,\n",
       "  'shape': array([], dtype=int32),\n",
       "  'shape_signature': array([], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/reshape_1/Reshape/shape/2',\n",
       "  'index': 4,\n",
       "  'shape': array([], dtype=int32),\n",
       "  'shape_signature': array([], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/conv1d_2/conv1d',\n",
       "  'index': 5,\n",
       "  'shape': array([ 8,  1,  3, 13], dtype=int32),\n",
       "  'shape_signature': array([ 8,  1,  3, 13], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([0.01386269, 0.00588729, 0.00696319, 0.00737325, 0.00774639,\n",
       "          0.00689075, 0.00741341, 0.00935394], dtype=float32),\n",
       "   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/reshape_1/strided_slice',\n",
       "  'index': 6,\n",
       "  'shape': array([1], dtype=int32),\n",
       "  'shape_signature': array([1], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/reshape_1/strided_slice1',\n",
       "  'index': 7,\n",
       "  'shape': array([1], dtype=int32),\n",
       "  'shape_signature': array([1], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/conv1d_2/conv1d/Squeeze',\n",
       "  'index': 8,\n",
       "  'shape': array([3], dtype=int32),\n",
       "  'shape_signature': array([3], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/reshape_1/Shape',\n",
       "  'index': 9,\n",
       "  'shape': array([2], dtype=int32),\n",
       "  'shape_signature': array([2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/reshape_1/strided_slice2',\n",
       "  'index': 10,\n",
       "  'shape': array([], dtype=int32),\n",
       "  'shape_signature': array([], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/reshape_1/Reshape/shape',\n",
       "  'index': 11,\n",
       "  'shape': array([3], dtype=int32),\n",
       "  'shape_signature': array([3], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/reshape_1/Reshape',\n",
       "  'index': 12,\n",
       "  'shape': array([ 1, 50, 13], dtype=int32),\n",
       "  'shape_signature': array([-1, 50, 13], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.036910686641931534, -9),\n",
       "  'quantization_parameters': {'scales': array([0.03691069], dtype=float32),\n",
       "   'zero_points': array([-9], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/conv1d_2/conv1d/ExpandDims',\n",
       "  'index': 13,\n",
       "  'shape': array([ 1,  1, 50, 13], dtype=int32),\n",
       "  'shape_signature': array([-1,  1, 50, 13], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.036910686641931534, -9),\n",
       "  'quantization_parameters': {'scales': array([0.03691069], dtype=float32),\n",
       "   'zero_points': array([-9], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_1/conv1d_2/Relu;sequential_1/conv1d_2/BiasAdd;sequential_1/conv1d_2/conv1d/Squeeze;sequential_1/conv1d_2/BiasAdd/ReadVariableOp/resource;sequential_1/conv1d_2/conv1d',\n",
       "  'index': 14,\n",
       "  'shape': array([ 1,  1, 50,  8], dtype=int32),\n",
       "  'shape_signature': array([-1,  1, 50,  8], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.03273308649659157, -128),\n",
       "  'quantization_parameters': {'scales': array([0.03273309], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity_int8',\n",
       "  'index': 15,\n",
       "  'shape': array([ 1, 50,  8], dtype=int32),\n",
       "  'shape_signature': array([-1, 50,  8], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.03273308649659157, -128),\n",
       "  'quantization_parameters': {'scales': array([0.03273309], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'reshape_1_input',\n",
       "  'index': 16,\n",
       "  'shape': array([  1, 650], dtype=int32),\n",
       "  'shape_signature': array([ -1, 650], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.036910686641931534, 119),\n",
       "  'quantization_parameters': {'scales': array([0.03691069], dtype=float32),\n",
       "   'zero_points': array([119], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity',\n",
       "  'index': 17,\n",
       "  'shape': array([ 1, 50,  8], dtype=int32),\n",
       "  'shape_signature': array([-1, 50,  8], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.03273308649659157, 0),\n",
       "  'quantization_parameters': {'scales': array([0.03273309], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_details = interpreter.get_tensor_details()\n",
    "tensor_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADQAAAASCAYAAAAUjf3AAAAABHNCSVQICAgIfAhkiAAAA1ZJREFUSInd12moVVUUB/Dfs9EyLax8BBIqhSGUvkoIpYkIK8u0LwlJJQ1gA1SPJqhuRfAsjIZPzZkJalISUmKW0GDDBwspo+k1x7OZUp9Tvj6sfbj7Hs65TZ96Cy77nnXW3nv99/6v/7q3o9FoGEw2pPQ8Hy/ja/TjZ7yL2zCyYn4H5uIt/I6tKf5q7NFm37OwGt+kfXrxDE74m3nPwUD6XNIO0DXYHy/hfizGLjSwAaNL8QvxGMZgKR7B3mnuUgG4bPOxEl1YlWLXYwbewAV/AWY0HsTmqpd7lp6HY1tF3F24GTdhXvKdK07qc0zGj8m/F5bhPFyIJ7N1OtGNTTga32fvTsEruANP14DpwBP4Cc+mtVqsfENVYKQE4YjMNyuNCzIwsBO3pO9XldY5PO35tlYwsFbQ9pCaHAgqn4qLsaUqoAyozs5O44bM15nG3or4wteFAzP/J9ghbvTg0pwTcQDW1ORwFHoERV+tS7RMucK6MQwjcBymCjA9WUxxK2Mq5o/Nvo8XokGIzA24FxuxQtBnHM4RtXt5TZ6L8JWgfq21AzQqe16Fi/BD5luJ2bgWS1KyxZq3Z3EHlda+D1/gcVya+T8V9VamItyKSeJg+2tyRj3lOkUBdopaGSvkuCuLWYIXxeluxMMp2fdwpqAX/FFa+3osT8mPE6p6rKDpYtxdip8sbmUB3mwHph2gwjbhOZwu+tBT2bvdgibd6BOKN1f0lqmCSrSe+MlCtp8XN9sretd6zMS3uE6TsgXVPtYUmv8EqLAvxS1M0FrMu8TJTcRQIfvTUuxEQY8PsvjpaVxbscdWvJNympR8w3CkEIRtms10QDR7ovcNCHbU1lCVHZbGMoWqbA72FY13Z+bfJ4110lz4d6Rxu2jcVdYlgL+OjyQ65oDG41dBn9yG4E4cinX4JXs3HL+V4o8XarhZNMncXsOVuAwPCYoVdgamiJtYl3z9Sj9tMmskQAvxaOHMAU3DPULjPxM1MAonCU73aVUlQmb78b5oihOEIGwXYlLuUctFnzkNH4r67BOUmi6E6EbN+vvHlgNaI5RqCo4RDXGLKMhFeEBTmvMEzxe/v4biO3FaPUKay7ZbAL4izZuJ/dK6L6Q9Vv9bMNAx2P8+/O9t0AH6E048yUx/nPy3AAAAAElFTkSuQmCC\n",
      "text/latex": [
       "$\\displaystyle 3984$"
      ],
      "text/plain": [
       "3984"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_model_quant_file = pathlib.Path('int8-model.tflite')\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = X[test_image_index]\n",
    "    test_label = Y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    \n",
    "    return interpreter.get_tensor(output_details[\"index\"])[0]  # TODO: remove\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_file, model_type):\n",
    "  test_mfcc_indices = range(X.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_mfcc_indices)\n",
    "\n",
    "  accuracy = (np.sum(np.argmax(Y, axis=1) == predictions) * 100) / len(X)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy is 96.4296% (Number of test samples=3613)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference Implementation](https://github.com/tensorflow/tensorflow/blob/92f84571edb98bdb31f1e7b1e23f17bf2c1438e9/tensorflow/lite/kernels/internal/reference/conv.h#L101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()[0]\n",
    "input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "conv1_weight_details = tensor_details[5]['quantization_parameters']\n",
    "conv1_weight_scale = conv1_weight_details['scales']\n",
    "conv1_weight_zero = conv1_weight_details['zero_points']\n",
    "\n",
    "conv1_biases_details = tensor_details[1]['quantization_parameters']\n",
    "conv1_biases_scale = conv1_biases_details['scales']\n",
    "conv1_biases_zero = conv1_biases_details['zero_points']\n",
    "\n",
    "conv1_activation_details = tensor_details[14]['quantization_parameters']\n",
    "conv1_activation_scale = conv1_activation_details['scales']\n",
    "conv1_activation_zero = conv1_activation_details['zero_points']\n",
    "conv1_activation_max = 8.34693717956543\n",
    "conv1_activation_min = 0\n",
    "\n",
    "quant_conv1_weights = np.zeros(conv1_weights.shape)\n",
    "quant_conv1_biases = np.zeros(conv1_biases.shape)\n",
    "for i in range(conv1_biases.size):\n",
    "    quant_conv1_weights[:,:,i] = conv1_weights[:,:,i] / conv1_weight_scale[i] + conv1_weight_zero[i]\n",
    "    quant_conv1_biases[i] = conv1_biases[i] / conv1_biases_scale[i] + conv1_biases_zero[i]\n",
    "\n",
    "def quant_relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def quant_conv1d_single_kernel(x, weights, bias, x_scale, x_zero, kernel_scale, kernel_zero,\n",
    "                               activation_scale, activation_zero):\n",
    "    '''Perform convolution of a input feature map with a single filter and bias.\n",
    "    \n",
    "    featuremap dims are (time, n_coeffs), so (50, 13)\n",
    "    '''\n",
    "    out = np.zeros(x.shape[0], dtype=np.float32)  # output length is the same\n",
    "    x_pad = np.zeros((x.shape[0]+2, x.shape[1]), dtype=np.float32)\n",
    "    x_pad[1:-1,:] = x  # zero padding\n",
    "    for i in range(x.shape[0]):\n",
    "        section = x_pad[i:i+3,:]\n",
    "        #out[i] = quant_relu(np.sum(section * weights) + bias)\n",
    "        #acc = np.sum((section - x_zero) * (weights - kernel_zero))\n",
    "        acc = np.sum((section - x_zero) * weights)\n",
    "        acc += bias\n",
    "        multiplier = x_scale * kernel_scale / activation_scale  # convert to quantized multiplier\n",
    "        preactivation = multiplier * acc + activation_zero\n",
    "        #out[i] np.clip(activated, activation_min, activation_max)\n",
    "        #import ipdb\n",
    "        #ipdb.set_trace()\n",
    "        #out[i] = quant_relu(preactivation)\n",
    "        out[i] = preactivation\n",
    "    return out\n",
    "\n",
    "def quant_conv1d_multi_kernel(x, weights, biases, x_scale, x_zero, weight_scale, weight_zero,\n",
    "                              activation_scale, activation_zero):\n",
    "    n_kernels = weights.shape[2]\n",
    "    out = np.zeros((x.shape[0], n_kernels), dtype=np.float32)\n",
    "    for i in range(n_kernels):\n",
    "        kernel = weights[:,:,i]\n",
    "        kernel_scale = weight_scale[i]\n",
    "        kernel_zero = weight_zero[i]\n",
    "        out[:,i] = quant_conv1d_single_kernel(x, kernel, biases[i], x_scale, x_zero, kernel_scale, kernel_zero,\n",
    "                                              activation_scale, activation_zero)\n",
    "    return out\n",
    "\n",
    "def quant_max_pool_1d(x):\n",
    "    out = np.zeros((int(np.ceil(x.shape[0] / 2)), x.shape[1]), dtype=np.float32)\n",
    "    for j in range(x.shape[1]):\n",
    "        for i in range(int(np.floor(x.shape[0] / 2))):\n",
    "            out[i, j] = np.maximum(x[2*i, j], x[2*i+1, j])\n",
    "        if (x.shape[0] % 2 == 1):\n",
    "            out[-1, j] = x[-1, j]\n",
    "    return out\n",
    "\n",
    "def quant_dense(x, weights, biases):\n",
    "    x = x.flatten()\n",
    "    out = softmax(np.matmul(x, weights) + biases)\n",
    "    return out\n",
    "\n",
    "def quant_classify(features):\n",
    "#     out = np.zeros((features.shape[0], 3), dtype=np.float32)\n",
    "    out = np.zeros((features.shape[0], 50, 13))\n",
    "    for i in range(features.shape[0]):\n",
    "        x = features[i]\n",
    "        x = x / input_scale + input_zero_point\n",
    "        x = x.reshape((int(x.size / 13), 13))\n",
    "        conv1 = quant_conv1d_multi_kernel(x, quant_conv1_weights, quant_conv1_biases,\n",
    "                                          input_scale, input_zero_point,\n",
    "                                          conv1_weight_scale, conv1_weight_zero,\n",
    "                                          conv1_activation_scale, conv1_activation_zero)\n",
    "#         max_pool1 = quant_max_pool_1d(conv1)\n",
    "#         conv2 = quant_conv1d_multi_kernel(max_pool1, conv2_weights, conv2_biases)\n",
    "#         max_pool2 = quant_max_pool_1d(conv2)\n",
    "#         dense1 = quant_dense(max_pool2, dense_weights, dense_biases)\n",
    "#         out[i] = dense1\n",
    "        out = conv1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-149, -289, -140, -328, -385, -491,    7,  -39],\n",
       "       [-191, -188, -293, -332, -266, -239, -118, -122],\n",
       "       [-175, -173, -304, -271, -230, -209, -129,  -99],\n",
       "       [-128, -232, -277, -272, -231, -235, -160,  -62],\n",
       "       [-163, -229, -268, -296, -285, -205, -150, -107],\n",
       "       [-159, -230, -300, -273, -238, -189, -154, -111],\n",
       "       [-153, -189, -232, -248, -253, -264, -193,  -88],\n",
       "       [-165,  -91, -170, -215, -232, -250,  -68, -125],\n",
       "       [-122,  -82, -159, -228, -180, -220, -126, -134],\n",
       "       [-131,  -60, -191, -252, -168, -177, -171, -187],\n",
       "       [-172,  -78, -157, -265, -187, -201, -123, -149],\n",
       "       [-173,  -84, -186, -255, -193, -191, -154, -170],\n",
       "       [-157, -133, -279, -256, -183, -173, -150, -124],\n",
       "       [-136, -121, -245, -168, -200, -162, -208, -154],\n",
       "       [-109, -135, -116, -115,  -92, -132, -188, -172],\n",
       "       [-160, -250,  -18, -193,  -76, -121, -198, -102],\n",
       "       [-144, -230,   11, -201, -146,  -72, -238, -152],\n",
       "       [-132, -270,  -28, -181,  -57,  -57, -209, -101],\n",
       "       [-134, -247,  -53, -198,  -84,  -62, -191, -149],\n",
       "       [-129, -242,  -87, -161,  -98,  -43, -190, -180],\n",
       "       [-180, -244, -103,  -86,  -82,  -49, -150, -169],\n",
       "       [-112, -255, -158,  -52,  -83,  -34, -180, -187],\n",
       "       [-157, -260, -147,  -65, -108,  -86, -165, -167],\n",
       "       [-167, -241, -146,  -60, -110,  -66, -134, -165],\n",
       "       [-145, -226, -158,  -60, -106,  -54, -171, -200],\n",
       "       [-153, -246, -188,  -83,  -42,  -62, -152, -173],\n",
       "       [-187, -200, -161,  -61,  -79,  -46, -174, -169],\n",
       "       [-144, -240, -116,  -47,  -46,  -70, -185, -138],\n",
       "       [-140, -198, -138, -110,  -89,  -91, -209, -167],\n",
       "       [-183, -126, -115, -147, -103, -132, -189, -195],\n",
       "       [-165, -129, -125, -179,  -91, -133, -182, -220],\n",
       "       [-159,  -89, -142, -151,  -76, -140, -180, -238],\n",
       "       [-161,  -90,  -85,  -96, -119, -195, -157, -202],\n",
       "       [-156, -114,  -91, -146, -161, -188, -179, -224],\n",
       "       [-149, -111,  -92, -193, -156, -220, -156, -199],\n",
       "       [-142,  -90, -165, -189, -169, -223, -141, -256],\n",
       "       [-162, -114, -171, -202, -201, -176, -122, -179],\n",
       "       [-128, -230, -211, -127, -167, -189, -185, -131],\n",
       "       [-145, -173, -238, -156, -207, -150, -121, -180],\n",
       "       [-184, -205, -246, -150, -203, -149, -170, -176],\n",
       "       [-146, -243, -271,  -86, -187, -169, -234, -151],\n",
       "       [-146, -274, -247,  -74, -188, -151, -186, -147],\n",
       "       [-143, -307, -246, -119, -225, -178, -181, -194],\n",
       "       [-191, -306, -309, -245, -201, -140, -118,  -67],\n",
       "       [-170, -239, -335, -248, -302, -160, -154, -127],\n",
       "       [-161, -226, -322, -220, -227, -242, -116,  -95],\n",
       "       [-199, -163, -347, -267, -267, -177, -113, -156],\n",
       "       [-167, -227, -303, -232, -199, -229, -170,  -85],\n",
       "       [ -94, -291, -299, -198, -268, -207, -242,  -59],\n",
       "       [-255, -376, -195, -153, -332, -210,   41, -112]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_result = run_tflite_model(tflite_model_quant_file, [0])\n",
    "numpy_result = quant_classify(X[:1])\n",
    "my_pred = classify(X[:1,:])\n",
    "numpy_result.astype(int)\n",
    "#tflite_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True, False,  True,  True,  True,  True, False, False],\n",
       "        [False, False,  True,  True,  True,  True, False,  True],\n",
       "        [ True, False,  True,  True,  True,  True,  True,  True],\n",
       "        [ True, False,  True,  True,  True,  True, False,  True],\n",
       "        [ True, False,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True, False,  True,  True,  True,  True,  True,  True],\n",
       "        [False,  True, False, False, False,  True,  True,  True],\n",
       "        [ True,  True, False,  True, False, False,  True, False],\n",
       "        [ True,  True, False,  True,  True, False,  True,  True],\n",
       "        [ True,  True, False,  True, False, False,  True, False],\n",
       "        [ True,  True, False,  True, False, False,  True,  True],\n",
       "        [ True,  True, False,  True, False, False,  True,  True],\n",
       "        [ True,  True, False, False, False, False,  True,  True],\n",
       "        [False,  True,  True, False, False, False,  True,  True],\n",
       "        [ True,  True,  True, False, False, False,  True,  True],\n",
       "        [ True,  True,  True, False, False, False,  True,  True],\n",
       "        [ True,  True,  True, False, False, False,  True,  True],\n",
       "        [ True,  True,  True, False, False, False,  True,  True],\n",
       "        [ True,  True,  True, False, False, False,  True,  True],\n",
       "        [ True,  True, False, False, False, False,  True,  True],\n",
       "        [ True,  True,  True, False, False, False,  True,  True],\n",
       "        [ True, False, False,  True, False,  True,  True,  True],\n",
       "        [ True,  True, False,  True, False,  True,  True,  True],\n",
       "        [ True, False,  True,  True, False,  True,  True,  True],\n",
       "        [ True, False, False, False, False,  True,  True,  True],\n",
       "        [ True, False, False,  True,  True,  True,  True,  True],\n",
       "        [ True, False, False,  True,  True,  True,  True,  True],\n",
       "        [ True, False,  True,  True,  True,  True,  True,  True],\n",
       "        [ True, False,  True,  True,  True,  True, False,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True, False,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [False,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_result\n",
    "np.logical_and((my_pred==0), (tflite_result==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-128], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_activation_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-127.        ,   59.84857559,   80.46018219, -110.07582092,\n",
       "          127.        ,  126.99999237,  -54.62316895, -126.99999237],\n",
       "        [  21.9630146 ,   98.51624298,  -32.76836014,   24.05471992,\n",
       "          -14.2999773 ,   -8.27717018,  -29.89610481,  -37.39074326],\n",
       "        [  30.40066719,   39.2250824 ,  -36.42618179,   -8.2433691 ,\n",
       "           -2.4023962 ,  -19.72091484,  -69.71202087,    2.03873706],\n",
       "        [  -7.3085947 ,  -38.56336594,  -28.49256134,    9.91439533,\n",
       "          -31.11902809,   20.89669418,  -56.71468735,   42.77544403],\n",
       "        [  14.22246933,   15.38040924,  -87.23403168,   96.75441742,\n",
       "           17.87460518,   35.59344482,   43.77444077,  -27.10764313],\n",
       "        [  -1.02952313,   14.82881737,   11.56383419,   -9.6651001 ,\n",
       "           23.94236755,   20.30063248,   -7.64687967,    7.2720747 ],\n",
       "        [  19.92416763,  -23.60510254,  -14.15288162,  -43.06171799,\n",
       "           15.97456551,   61.60734177,    8.99171638,   25.44936943],\n",
       "        [   8.38902664,  -29.5775032 ,   14.68937492,   44.0976944 ,\n",
       "           25.80533791,    9.59197521,    3.51831245,    0.31929776],\n",
       "        [   1.61888909,  -36.46355438,   19.72838593,   11.03869343,\n",
       "          -24.2419014 ,    5.96991587,  -38.43082047,   -1.1156944 ],\n",
       "        [  -1.6538043 ,    5.13020277,   -5.98089457,   -4.37853241,\n",
       "           21.26410866,   14.75386715,   15.41645241,   -2.16936231],\n",
       "        [   1.96539474,   12.19613171,  -55.04349136,  -10.63511086,\n",
       "          -32.22550583,   39.760952  ,   36.08283997,   -7.7725091 ],\n",
       "        [  -2.99121118,   21.91980171,   13.15310574,    5.89673758,\n",
       "          -45.77690506,    5.18401289,   -8.80014038,  -39.38319778],\n",
       "        [   2.12841105,  -31.23104095,    7.62566423,   16.52981949,\n",
       "           27.79096603,   -8.77966213,  -30.68313789,   62.57713318]],\n",
       "\n",
       "       [[ 121.16047668,   28.34907532,   37.43829346,  127.        ,\n",
       "           69.69074249,  108.65370941,   51.51520157,   69.39640808],\n",
       "        [   1.12118053,   37.07454681,   30.71813583,   42.81791306,\n",
       "           12.31804562,  -27.88460922,  127.        ,  -21.0907402 ],\n",
       "        [ -56.3882103 ,  105.04536438,   -4.68091297, -112.37902069,\n",
       "          -35.66943359,  -11.08654404,   79.15355682,   27.94179153],\n",
       "        [  -3.71384645,  -31.60181618,   20.6568737 ,   -2.65468454,\n",
       "           23.59636116,  -11.50644302,  101.35555267,   -3.6385963 ],\n",
       "        [ -33.33830261,   31.51070786,  -68.08905792,   31.7344799 ,\n",
       "          -32.55851746,  -37.53195953,    6.7443881 ,   21.12726212],\n",
       "        [  -4.48753881,    9.47680569,   27.01507187,  -43.51187897,\n",
       "           15.5977459 ,    0.7485671 ,  -25.01822853,   24.66810036],\n",
       "        [  -3.29961514,  -57.26028824,   50.48552322,  -15.24959755,\n",
       "          -29.17282867,   16.58138657,   23.52544594,   -6.54180908],\n",
       "        [ -15.18305492,    1.0093025 ,    3.82552719,   36.91268158,\n",
       "           13.64332485,   41.92505264,   12.67277622,   17.80222893],\n",
       "        [   2.12520742,    5.44853306,    4.63802624,  -16.38867188,\n",
       "          -11.51639175,    0.32470784,   37.31791687,   22.55205917],\n",
       "        [  -2.55505252,  -20.59498787,   36.37100983,   -2.76750493,\n",
       "          -24.156147  ,  -13.03165627,  -49.94734573,   -6.1500001 ],\n",
       "        [   4.70587349,  -39.50081253,  -18.47156906,  -22.07009888,\n",
       "            7.36570358,  -22.10033989,   23.48653412,   35.15647507],\n",
       "        [  -4.56112957,    5.4278965 ,   12.64909363,   33.41524124,\n",
       "           42.6516037 ,  -28.00747108,  -10.37054062,   10.59615612],\n",
       "        [   1.82529366,   22.41085434,  -18.59022903,    1.51457238,\n",
       "           14.83208179,   22.5620594 ,    5.05967617,  -17.66705704]],\n",
       "\n",
       "       [[  -3.19211483,   56.81959152,   55.01965332,   94.75804901,\n",
       "           34.3720665 ,   35.01474762,  -57.56814575,   17.99090004],\n",
       "        [  -5.4542799 ,   14.89205074,  127.        ,    3.67714953,\n",
       "            3.02829242,  -62.51672745,  -41.9315834 ,  -15.49270058],\n",
       "        [   5.87069178,  101.61670685,  -46.8803215 ,  -59.12686539,\n",
       "            2.52042079,   -4.99159479,   30.8793354 ,  -12.04819298],\n",
       "        [   8.13111877,   46.3745079 ,   13.14081192,   -3.11804414,\n",
       "           -3.07019949,  -19.88163185,  -79.39297485,  -22.58643723],\n",
       "        [  15.95778656, -127.00000763, -106.52609253,  -33.77157593,\n",
       "          -40.5010643 ,   62.23905182,  -22.67459679,   26.74171257],\n",
       "        [   0.7455315 ,   52.54138184,  -18.07779121,  -29.48084068,\n",
       "          -18.94440079,  -18.54138374,   27.33239746,   10.990839  ],\n",
       "        [  -0.45122838,  -37.47304535,   30.14004326,    6.42524719,\n",
       "           17.27070618,  -19.64798355,  -11.56787491,   29.98711014],\n",
       "        [   6.22225809,   -5.98191118,   18.05960655,  -10.42705727,\n",
       "            5.58413649,  -14.46296024,    2.74437404,  -10.54950428],\n",
       "        [   1.09736311,    6.94113827,  -58.58441544,   -3.10267258,\n",
       "           28.04079247,   -2.75341702,  -16.12582779,    9.0674963 ],\n",
       "        [   4.03829813,   12.82113171,   -0.3699896 ,    5.1661396 ,\n",
       "           30.08430099,   17.03561974,   -4.8892808 ,    3.84901571],\n",
       "        [  -2.69534445,    2.63163209,  -13.2824831 ,   14.41769409,\n",
       "            4.44273806,   16.11949539,  -32.75727081,   -8.78114986],\n",
       "        [   0.2243904 ,   32.23841095,  -24.94870758,   -4.84980345,\n",
       "           -3.74495125,   18.93060684,    4.95004892,   -7.16951609],\n",
       "        [  -4.04411602,    4.89231491,   11.34927464,  -27.29413795,\n",
       "           37.10203171,    0.54150224,   -4.04834509,   -7.35848045]]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_conv1_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scales': array([0.01386269, 0.00588729, 0.00696319, 0.00737325, 0.00774639,\n",
       "        0.00689075, 0.00741341, 0.00935394], dtype=float32),\n",
       " 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 'quantized_dimension': 0}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_weight_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB0AAAAVCAYAAAC6wOViAAAABHNCSVQICAgIfAhkiAAAAkBJREFUSIm91lmoT1EUBvDfRZmjkFsKId5kSldKlCFDhnc8EN6UIcPbTTIVriclCaUIhZAQRWTmCUXIkBBChq4MD3v/OXfffQzd+Orfqm+dtb591lnfOf+q2tpa/xvNSvideI62Teg9GN8w+09Eh2A61uB9kpuI43iMj7iHvRiW6XMVB7AS7X4nugpvsTnh1+IwBuEYNuEapuBcPGiK1ajG/CJZlTzTvriNrZhb4KvxBC/QXxh9BaNwCvfRKyN8C21i7guN73QWqrAn4XvEay8mgnAa79AlIwi70R2jK0QqOjqe5kLC30E9hqJzkhuB9jhZInouxjEVokUh2RYDhHGkC/QKS7EBN4UFeYnemIwTmFcierlwuEai3dAcT0uK6/AA2zCnwN/Fdo3HXsEbfBJGjIbj7RTj65LiJdgXBXoLkxks2GYX1pXUESb147EURT/G2CpTNFKwzCEsjEIfBMtMEzZ7kfz2QutC/wailfF00hiTYjydyX3ApdhrYCbfDB0L/RuIPhV82C9T2DLGMltU+PpMrp9gwxs50W84I8y+T1J4Nsa5wsIVMR7DhWU5nxGtifHHlFKf7o9xXMLvE3zYVbDUDj+f8ZF4J8sEG6UYK3j/4K9En2Fmwn/FBCwQfDpNWJwaHI2H3JQR7ICpwjv7UYVskVxUH4tXCUtxvZD7LHi1LtO8DDMFN6wvkrmvzEY8xIq/aJ5DaywXpne2mMiJfsIMXNG0j3hPbMHiNJGOt4Iz8dcU3EJtLlH2d+Wf4jsYPX2K2F2lVgAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$\\displaystyle \\left( 8\\right)$"
      ],
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
